"comment_id","user","time","message","parent_id"
"ltjktid","iwasjusttwittering","2024-10-24 17:18:55 UTC","Core part:

> Penguin Random House didn't become the largest publisher in history by publishing better books or doing better marketing. They attained their scale by buying out their rivals. The company is actually a kind of colony organism made up of dozens of once-independent publishers. Every one of those acquisitions reduced the bargaining power of writers, even writers who don't write for PRH, because the disappearance of a credible bidder for our work into the PRH corporate portfolio reduces the potential bidders for our work no matter who we're selling it to.

> I predict that PRH will not allow its writers to add a clause to their contracts forbidding PRH from using their work to train an AI. That prediction is based on my direct experience with two of the other Big Five publishers, where I know for a fact that they point-blank refused to do this, and told the writer that any insistence on including this contract would lead to the offer being rescinded.

> The Big Five have remarkably similar contracting terms. Or rather, unremarkably similar contracts, since concentrated industries tend to converge in their operational behavior. The Big Five are similar enough that it's generally understood that a writer who sues one of the Big Five publishers will likely find themselves blackballed at the rest.

> ...

> The biggest predictor of how much money an artist sees from the exploitation of their work isn't how many exclusive rights we have, it's how much bargaining power we have. When you bargain against five publishers, four studios or three labels, any new rights you get from Congress or the courts is simply transferred to them the next time you negotiate a contract.

‚ÄîCory Doctorow",""
"ltjo7ls","IndigoBlueBird","2024-10-24 17:35:34 UTC","I can‚Äôt believe we‚Äôre using AI to automate the fun, creative parts of being human instead of focusing on the boring, menial parts üòµ‚Äçüí´

ETA: guys I wasn‚Äôt asking for an explanation in AI. I work in a tech adjacent role, I know how we got here. I was expressing dismay that we‚Äôre here at all, not bafflement on how it happened",""
"ltjsbpa","mykepagan","2024-10-24 17:55:40 UTC","More like:

YOU can‚Äôt train an AI using our books‚Ä¶ Only WE can train an AI using our books.‚Äù",""
"ltkc04h","goodbye-for-now","2024-10-24 19:33:43 UTC","After reading some of the comments:

1. LLMs (Large Language Models) are not intelligent - these are very sophisticated statistical models taught on vast amounts of data (Big Data) how to predict word patterns. And it is only one kind of an AI, not the whole of it.¬†

2. Automatization, robotization and AI use are three different things that can, (and quite often do) but don‚Äôt necessarily have to overlap.¬†

3. AI use in industrial settings is a thing, but in my experience it‚Äôs more often something like predictive maintenance (used e.g. for predicting breakdowns in machines) or vision systems (e.g. finding faulty products on a production line).

4. AI ethics is very complex, relevant, and very hotly debated topic now. I‚Äôd urge people to try and learn more because generative AI is just a tip of iceberg when it comes to ethical issues of AI.",""
"ltjner1","Genoscythe_","2024-10-24 17:31:38 UTC","Cory Doctorow has been always a gem when it comes to not falling for AI hype, but neither for the manipulative anti-AI bandwagon's trojan horse for shutting down the last remaining freedoms that we have in an increasingly controlled media under the banner of IP maximalism.",""
"ltk6txm","hearing_aid_bot","2024-10-24 19:07:49 UTC","Shocked that the company who exists to hoard intellectual property is interested in exploiting said hoard and preventing others from doing the same. It's a good thing authors can self publish easily and make the same amount of money on their own as they can by selling their rights to the corporate version of Smaug. Copyright law sure is good for authors /s",""
"ltlee6j","Darksun-X","2024-10-24 22:57:53 UTC","Business ruins everything.",""
"ltn3tcg","BMCarbaugh","2024-10-25 05:53:21 UTC","This is why the Author's Guild has recently given writers suggested language to include in contract provisions that basically says ""AI rights are a specific right, like film rights, that I hold onto until we make a deal saying otherwise"".",""
"ltk396w","YsoL8","2024-10-24 18:50:00 UTC","One thing I have seen absolutely no one address is, how the hell does anyone expect to prove an AI was trained with something they own or that something they made was based on it?

Without that you can say what you want and it'll make no difference.",""
"ltjkqc0","arlondiluthel","2024-10-24 17:18:28 UTC","Of course it's not the same. You think their language wasn't intentional?",""
"ltl9vgj","CMC_Conman","2024-10-24 22:31:14 UTC","I'm trying to figure out why PRH needs an AI",""
"ltmb0si","tapdancinghellspawn","2024-10-25 02:15:27 UTC","Artists, programmers, and anyone else who uses their intellect to work need to think about joining forces to protect themselves because if you leave it up to Wall Street and corporations, you are gonna be in trouble.  Also, politicians are barely waking up to this problem so don't count on them.",""
"ltoo1bu","mrslipple","2024-10-25 14:01:51 UTC","Twist: they've already trained an AI with your books.",""
"ltmb06v","gw2master","2024-10-25 02:15:20 UTC","This whole thing is fucking ridiculous.  If the AI reads your book and uses the information in it in a way that does not violate copyright what's the problem?  I can read a book and summarize it to my friend.  Should I get sued?",""
"ltoywfy","HumanID","2024-10-25 14:59:51 UTC","A new class of writer will emerge that creates stories that utilize AI, basically, writing using the AI as the canvas, that cannot be mimicked by AI for a long time. 

Pen and paper is a medium for writing, writers will never die but mediums will change.",""
"ltymdzt","_the_last_druid_13","2024-10-27 04:13:21 UTC","This is partly why Hollywood is only doing reboots.

Why write if your work is stolen the moment you start typing? For the love of the game? Well if we‚Äôre to even play the game we kind of need the money to be generated by our work.

This is why I tell everyone we should push for UBI/Basic based off of Big Data profits. Basic would include housing/repair/upkeep + healthy food/clean water + healthcare to the fullest extent.

Corporations can just buy up homes like billionaires can buy up BitCoin, we will be left with nothing.

Food subsidies and the DPW already work off taxes.

Healthcare is a broke joke when an insurance company can charge $500 for 2 Advils while in hospital. It‚Äôs egregious especially when nurses, who are angels on earth and hold one of the Top 3 Most Difficult Jobs, are paid garbage with garbage benefits.

‚ÄúNo one wants to work anymore‚Äù - FALSE. People would be inclined to work especially with the Basic Social Net/Hierarchy of Needs met; you‚Äôd need clothes, technology, furniture, vacations, restaurants/dates/takeout, and recreational/hobby products. 

Throw in the whole Reparations thing too into UBI/Basic. I listened to a segment the other day explaining that reparations would cost tens of trillions, which no one has, so many are asking for non-monetary examples, HENCE UBI/Basic.",""
"ltlrsov","No_Landscape4557","2024-10-25 00:17:47 UTC","Asking the dumb question. Hasn‚Äôt ‚ÄúAI‚Äù already basically ‚Äúread‚Äù aka scanned basically every book and webpage in existence? As this point it not gunna get any better or smarter.",""
"ltmcpzb","ReallyGottaTakeAPiss","2024-10-25 02:26:03 UTC","The infinite monkey theorem applies to statistics, but the logic applies to AI and writing very well. Language is a finite construct with subjective interpretations and eventually, a random computer simulation tasked with combining every possible word known man will eventually write everything that has already been written.

I think people have a lack of understanding when it comes to AI and discount the human input and intent required to yield plagiarized writing. Additionally, we can still coexist with such technology while giving proper credit where it‚Äôs due.

I still think this blog post points out where we went wrong with modernizing the music industry and sounds a great warning on representing and compensating people properly. Something I never really considered yet‚Ä¶

Great read, thanks for sharing.",""
"ltki2sp","Maycrofy","2024-10-24 20:03:57 UTC","Gonna be the doomer and say that the era of paid artists is coming to an end. It won't be possible to make money from creativity anymore, anyhting you want to do you'll have to do for the love of it. sad.",""
"ltmtq19","HeathrJarrod","2024-10-25 04:23:54 UTC","Example: can ai write ?

Giulio entered, shadows thick as night,  
His heart a storm of grief, his steps unsure.  
The torch he held flickered, its feeble light  
But barely casting warmth upon the floor.  
And there she lay, his love, in deathly peace,  
As pale as marble, still as frozen stone.  
Her beauty, though untouched by life‚Äôs cruel cease,  
Brought tears to eyes that now wept all alone.

‚ÄúO Lucrezia,‚Äù he whispered soft, his voice  
A trembling note that echoed through the tomb.  
‚ÄúToo soon art thou departed from my choice,  
And left me naught but sorrow‚Äôs heavy gloom.‚Äù  
He knelt beside her, fingers cold as ice,  
And brushed her cheek, so chill beneath his hand.  
No breath did stir, no heartbeat would suffice,  
To wake her from that far and silent land.

With trembling lips, he kissed her, once, then twice,  
As if his love could breathe her back to life.  
But death held firm; his kiss would not suffice,  
No magic here could cut through fate‚Äôs sharp knife.  
From deep within his cloak, he drew the draught,  
A poison dark that promised peaceful rest.  
‚ÄúFor without thee,‚Äù he said, ‚ÄúI am but naught,  
To live apart from thee, I am oppressed.‚Äù

He drank it down, the bitter venom strong,  
Its tendrils curling through his veins with speed.  
His breath grew short, his life not long for song,  
Yet still he reached for her in time of need.  
‚ÄúForgive me, love, I could not wait,‚Äù he said,  
As darkness clouded o‚Äôer his fading sight.  
His body fell beside her, cold and dead,  
His spirit slipping into endless night.

But soft! What light doth now within her stir?  
Her eyes, once closed in sleep, begin to wake.  
Her chest, with breath renewed, begins to whirr,  
As if from death‚Äôs cold grasp she doth now break.  
She sits, confused, her heart a pounding drum,  
Her gaze upon the figure by her side.  
‚ÄúGiulio!‚Äù she cries. ‚ÄúMy love, what hast thou done?  
Awake! Awake! I live‚Äîthou shouldst not hide!‚Äù

She grasps his hand, so cold within her own,  
And shakes him, tears cascading down her face.  
‚ÄúThou must arise, for I am not alone!  
I live, Giulio, rise from death‚Äôs embrace!‚Äù  
Yet silence answers her, and death remains,  
The empty vial beside him tells the tale.  
She kisses him once more, but naught she gains‚Äî  
His lips are still, his body frail and pale.

‚ÄúWhy didst thou act so rash, my love, so swift?  
Why couldst thou not but wait a moment more?  
Now death hath ta‚Äôen thee as his final gift,  
And left me broken on this lonely shore.‚Äù  
Her sobs, like thunder, echoed ‚Äògainst the stone,  
But in her grief, her gaze fell on his blade.  
‚ÄúThen I shall follow thee, I shan‚Äôt bemoan,  
For death with thee is not a price o‚Äôerpaid.‚Äù

She drew the dagger from its silken sheath,  
And pressed its point against her tender breast.  
‚ÄúIf thou canst not return to life from death,  
Then I shall join thee in eternal rest.‚Äù  
With one sure stroke, she plunged the blade within,  
And crimson poured upon her gown of white.  
Her life slipped swiftly from its mortal skin,  
As darkness overtook her fading sight.

Beside her love she fell, their hands entwined,  
Their fates now sealed, as one in death aligned.",""
"lto1jmt","hollowtiger21","2024-10-25 11:36:38 UTC","Well never heard of this corporation before, but now i know it‚Äôs definitely garbage.

Just goes to show that GenAi, & LLM and all the shills are not only morally and ethically bankrupt, but also hypocritical. 

But exploitation, plagiarism and data scrapping machine go brrr.",""
"ltjujtc","atticdoor","2024-10-24 18:06:33 UTC","But then, when a human reads a book and later writes a book of their own, haven't they been ""trained"" on that book and all the books they read before in their life?  So long as AIs are programmed not to plagiarise, just as humans know not to copy a pre-existing book too closely, what's the problem?",""
"ltkm7cx","elmonoenano","2024-10-24 20:24:33 UTC","On the flip side, smaller presses are growing b/c of this. Joe Biel at Microcosm talks about it in his book A People's Guide to Publishing. Numbers are hard to pin down but Indies are increasing their market share and may be close to parity with the Big 5. Some people even put them much higher, but a lot of times these count self publishers. They still can't offer more money b/c they don't have the giant old catalogs still making them money. But they can outcompete on other contract terms like the AI clause.","ltjktid"
"ltjz6b5","Kessonl","2024-10-24 18:29:33 UTC","I worked for them and to say it‚Äôs colony of dozens of once independent publishers is an understatement. They own the largest self publishing arm in the county which has close to a dozen different independent publishers when I left.","ltjktid"
"ltjsg2e","jonassn1","2024-10-24 17:56:16 UTC","Maybe the gowerment/EU should step in with a investigation for cartelcreation","ltjktid"
"ltl8l98","merurunrun","2024-10-24 22:23:44 UTC","Like basically everyone with any money/power who voices concerns over AI, it's only a tactic to delay the competition until they're in a proper position to exploit it.","ltjktid"
"ltmd4ir","MythReindeer","2024-10-25 02:28:36 UTC","Capitalism inevitably drives toward cartels and monopoly, true.","ltjktid"
"ltkzcr7","10ebbor10","2024-10-24 21:31:56 UTC","This is why the ""AI art is theft"" is such a self defeating argument.

You're arguing that AI technology should be tied to copyright, to some kind of training right, and all that does is allow the big corporations to monopolize it.","ltjktid"
"ltjw2dw","ECEXCURSION","2024-10-24 18:14:03 UTC","My favorite thought is one AI writing books and another AI reading them because humans can't be bothered.

Grim future","ltjo7ls"
"ltjq0dq","throw-away_867-5309","2024-10-24 17:44:19 UTC","Because making the AI actually able to do the boring, menial parts costs significantly more and pays significantly less in the short term, so the people doing these think ""why do that when lot of money now?""","ltjo7ls"
"ltkel4t","MajorPhaser","2024-10-24 19:46:33 UTC","Someone much smarter than me said this about the current state of AI: It‚Äôs intended to give wealth access to talent and block talent from accessing wealth.  

I don‚Äôt know if that‚Äôs accurate, but every use case I see certainly makes it feel true.","ltjo7ls"
"ltk0sge","tikhonjelvis","2024-10-24 18:37:39 UTC","AI is a solution in search of a problem. It's being built out based on what the technology can do, not what anybody specifically *wants* it to do.

Some people had the idea to scale natural language neural nets, tried it out and got fancy text and image generators. Now folks are scrambling to figure out what we can actually *do* with these generators‚Äîand it turns out that it's mostly generating text and/or images, with everything else requiring way more research and engineering.

It turned out in a stupid way but for engineering and systemic reasons, not because that's what anybody wanted. (I believe a lot of the scientists and engineers involved really do want a more general AI that can handle all sorts of menial tasks, but that's not what they've built and there's no clear path to get there either.)

It's not even a matter of financial incentives. There's way more money in automating boring tasks for large corporations than anything to do with literature or art. Today's large language models just aren't particularly good for that sort of thing.","ltjo7ls"
"ltjp8bv","LevTheDevil","2024-10-24 17:40:32 UTC","It's because the creatives were too busy being creative and left the money minded to amass. Now they want to cut the creatives out so they can keep all that money because they don't actually understand the product they've been selling or what it means to people. 
Creatives need to unionized and those unions need to fight back. It's the only hope of getting things to a better place.","ltjo7ls"
"ltldrhv","WhimsicalWyvern","2024-10-24 22:54:11 UTC","We are focusing on the boring parts. You just aren't hearing about it.

Google has developed tools to automate medical tests that rely on radiologists looking at images.
https://www.zdnet.com/article/google-and-bayer-announce-an-ai-platform-to-cut-radiologists-workloads/

Multiple companies are trying to perfect self driving cars.
https://en.m.wikipedia.org/wiki/Self-driving_car

There's an enormous number of people creating AI tools to clean your data.
https://cocoon-data-transformation.github.io/page/clean

Automation, including the use of AIs, is being pushed hard in manufacturing.
https://www.arm.com/glossary/ai-in-manufacturing#:~:text=There%20are%20many%20applications%20for,data%20analysis%20and%20decision%2Dmaking.

Here's a graph of number of people in manufacturing vs how much stuff gets produced:
https://www.pewresearch.org/short-reads/2017/07/25/most-americans-unaware-that-as-u-s-manufacturing-jobs-have-disappeared-output-has-grown/
(And that was back in 2017!)

Healthcare uses AI to do medical research.
https://www.sciencedirect.com/science/article/pii/S1532046420302999#:~:text=Patient%20representation%20learning%20refers%20to,using%20advanced%20deep%20learning%20methods.

SpaceX uses AI to fly their rockets.
https://www.thecommunityai.org/ai-blog/ai-on-spacex

Not to mention all the programmers who use LLMs as an assistant to scrape documentation of stack overflow.","ltjo7ls"
"ltkcx6d","Deleted","2024-10-24 19:38:19 UTC","I think they're trying to edge out poorer artists and creatives, so that eventually only the rich will be able to afford any sort of artistic hobbies while the rest of us are working at cash registers and assembly lines for scraps or too busy bickering on social media to notice. Only the rich will be able to tell their stories and spread their messages. The rest of us will be drowned out.¬†","ltjo7ls"
"ltkeoaz","RealisticSolution757","2024-10-24 19:47:00 UTC","Right now AI isn't good enough to do the other shit by itself, by a wide margin. And who's to say it can write a good book? 2 years in what has chatGPT "" published""? Genuinely curious. 

And AI may stagnate if we don't have more breakthrough in chip making too, I wouldn't be too worried honestly. These projects will end up like Amazon's Whole Foods ""no cashier/self check outs"" AI that turned out to be 1k indians mouse clicking and looking at cameras lol","ltjo7ls"
"ltkeqlw","Televisions_Frank","2024-10-24 19:47:19 UTC","It's because the guys doing the menial labor don't potentially cost you a piece of the profits and these CEOs always seem kinda pissed *they* aren't the creative one.","ltjo7ls"
"ltkyq06","Top_Conversation1652","2024-10-24 21:28:35 UTC","When the boring, menial parts go wrong, massive lawsuits occur.

The fun stuff doesn‚Äôt kill people.

If you have a flaky, unreliable product that people tend to view as infallible, you‚Äôre better off focusing on things that don‚Äôt require accuracy.","ltjo7ls"
"ltlqcmy","WTFwhatthehell","2024-10-25 00:09:06 UTC","People simply tried for everything and some things turned out to be easier to automate than others. 

Nobody declared ""We shall figure out how to automate X first"". 

Spinning thread and writing text: no problem.

Folding a fitted sheet: will probably be the last unsolved problem in automation.","ltjo7ls"
"ltki6eo","Twokindsofpeople","2024-10-24 20:04:27 UTC","The boring menial parts are harder to automate.  Shit, just imagine how incredible the human hand is.","ltjo7ls"
"ltlapfx","KamikazeArchon","2024-10-24 22:36:10 UTC","It's because we mostly did the boring, menial parts already. 

Seriously, do you know how much time people used to spend just on washing dishes and cleaning clothes? Farming? Simply *walking*?

We just got used to not doing those things so now we rarely notice it.","ltjo7ls"
"ltjyfy5","Baozicriollothroaway","2024-10-24 18:25:55 UTC","What do you mean? Car assembly lines, product packaging and accounting logs sound fun to you? Most boring tasks can be/have been automated already, only certain tasks related to art, medicine and law remain.¬†","ltjo7ls"
"ltkj8g5","RogueModron","2024-10-24 20:09:45 UTC","Because the people making ""AI"" are neither fun nor creative.","ltjo7ls"
"ltme16e","Flimsy_Demand7237","2024-10-25 02:34:18 UTC","It's sad that a lot of people are just deeply uncreative, money-hungry, and lazy, and then AI somehow became the gift to them to pretend to be creative and possibly muscle out the actually creative works from creative people and flood these spaces.","ltjo7ls"
"ltqf875","littleseizure","2024-10-25 19:26:34 UTC",">instead of focusing on the boring, menial parts

We're doing both in parallel -- lots of people are doing AI, different people focus on different aspects.  Some people are working on the existing and publicly available text/image generators, others are working on better ways to run QC on assembly lines or drive across traffic-filled cities.

The text/image generators have a ton of uses, but they do tend to come down to text and images.  The lowest hanging fruit there is usually creative, unfortunately","ltjo7ls"
"ltjtvu6","ArchfiendJ","2024-10-24 18:03:16 UTC","We already did it with automation. The only thing that changed was the amount of profit for the 1%","ltjo7ls"
"ltjwgfq","sawbladex","2024-10-24 18:16:00 UTC","I mean, 

we developed printing press and killed illuminated manuscripts.","ltjo7ls"
"ltk0vjj","w-wg1","2024-10-24 18:38:05 UTC","What you find fun, others find boring, and vice versa. We are using it to optimize everything","ltjo7ls"
"ltmrtrb","HeathrJarrod","2024-10-25 04:08:47 UTC","Use an Ai for nsfw stories‚Ä¶ those are just lazy reading enough to work.   Reading nsfw is not about the big overarching story.  It doesn‚Äôt need to be","ltjo7ls"
"ltkgypq","Exist50","2024-10-24 19:58:23 UTC","> LLMs (Large Language Models) are not intelligent - these are very sophisticated statistical models taught on vast amounts of data (Big Data) how to predict word patterns

I think the problem here is trying to assign a particular definition to intelligence. In particular, is intelligence architectural, or an emergent behavior from simple mechanisms at scale?","ltkc04h"
"ltkbdve","Exist50","2024-10-24 19:30:36 UTC","Yes. The problem with a lot of the pseudo-legal arguments being used against AI is that they inevitably amount to a huge extension of copyright law, something which is not going to benefit smaller creatives. 

For example, if you argue that AI art inherently infringes copyright because it learns from existing works, under current copyright law, you'd have to extend that to pretty much any human-produced work as well (what artist hasn't been influenced by past works?). I would be very cautious about setting that precedent...","ltjner1"
"ltjsuy2","RamadamLovesSoup","2024-10-24 17:58:15 UTC","This was my first article of theirs I'd come across and boy was it a well-written and nuanced breath of fresh air.","ltjner1"
"ltr3qlu","Deleted","2024-10-25 21:38:15 UTC","To be honest, those contracts are pretty much garbage these days anyway. The basics of a boiler plate are an advance of $2-5k, free editing and a free book cover. And access. Forgot about that. Access to the Big 5 and all of their tentacles. 

What you don't get:
-Marketing help
-Monetary or other assistance for book tours and signings. 
-Book tours and signings.
-Help with press attention.

Unless you're big or on the rise anyway.

Oh and they won't take your manuscript unless it's thoroughly edited already, marketable and in line with current trends, (in that vein) similar to titles that have come out in the last three years (but not too similar)...and attached to a preexisting social media presence. 

So what are you getting, ultimately? A royalty rate of 15% after you've made back your sign on bonus, a competent editor you don't have to pay out of pocket for, a book cover design you don't have to pay for (saving you about a month's income between those two services), and a giant middle finger from the money department who doesn't believe you'll make that $2-5k back for them.","ltk6txm"
"ltk7n48","Dababolical","2024-10-24 19:11:53 UTC","I imagine you **might** be able to figure out during discovery through a lawsuit, but I am not completely certain. Maybe if the model is over fit, you can coerce the trained text out of it, but that's just an idea and relies on a flawed model.","ltk396w"
"ltl2qth","mjfgates","2024-10-24 21:50:20 UTC","The usual method is to prompt the LLM with quotes from the work you want to check the LLM against, and if what you get back is recognizably more of that work, you know. Pretty reliable by all accounts.","ltk396w"
"ltkyv3c","TonicAndDjinn","2024-10-24 21:29:20 UTC","One way is what the New York Times did in preparation for their lawsuit against openai: they prompted chatgpt with long passages of their articles, and it completed them with text matching the original article. This is not something it could do if it hadn't been trained on the articles, and moreover, if the weights in the model did not encode enough information about the article to reconstruct it.","ltk396w"
"ltkdo4z","Exist50","2024-10-24 19:42:00 UTC","> One thing I have seen absolutely no one address is, how the hell does anyone expect to prove an AI was trained with something they own or that something they made was based on it?

Moreover, can you apply the same restrictions to humans? So if someone ever reads a book by this publisher, they can never write anything again without that publisher's permission, lest it be ""contaminated""?","ltk396w"
"ltmgh58","dodgyville","2024-10-25 02:49:48 UTC","Part of the problem is these AI companies are attempting to launder the stolen data. They could easily include citations in the datasets when training but they don't and then say ""oh there's no way of telling where the output came from""","ltk396w"
"ltjpvnf","Deleted","2024-10-24 17:43:40 UTC","[deleted]","ltjkqc0"
"ltmh1bj","dodgyville","2024-10-25 02:53:21 UTC","It's not ""reading the book"". A company is deliberately taking an author's work without consent, generating a model of it in a dataset, and then trying to sell that dataset or the output of that dataset to the author or their competitors... while also telling the author their work is worth nothing.","ltmb06v"
"ltoxe0z","dicemonkey","2024-10-25 14:52:08 UTC","You are oversimplifying the problem ‚Ä¶.vastly.","ltmb06v"
"ltshhj9","Sansa_Culotte_","2024-10-26 02:49:30 UTC","> A new class of writer will emerge that creates stories that utilize AI, basically, writing using the AI as the canvas, that cannot be mimicked by AI for a long time. 

And it's obvious why this would be attractive to a publisher: You hire ""literary consultants"" to ""edit"" your AI generated garbage into a readable text, but retain all copyright to the ""original"" ""AI generated"" text and can pay the ""literary consultant"" a pittance even if the novel turns out to be a bestseller. Essentially turning authors from creators into hired hands to create a product that you own. 

That's essentially the selling point of generative AI at this point. 

Of course generative AI is a ridiculously costly resource black hole that generates mostly enormous amounts of unusable garbage, but it's an awesome story to sell to investors to make number go up.","ltoywfy"
"ltn39sv","Exist50","2024-10-25 05:48:07 UTC","> As this point it not gunna get any better or smarter.

Maybe not from sheer volume of data. How that data is used, however...","ltlrsov"
"ltngdx0","My_sloth_life","2024-10-25 08:06:06 UTC","No. Some systems can prevent their work being crawled. The likes of academic publishers such as Elsevier, have stopped them crawling their works because they want to produce their own AI.","ltlrsov"
"ltnhf9x","somegetit","2024-10-25 08:17:33 UTC","First, it is about getting smarter. For example, let's say they'll come up with a new learning algorithm (I'm way simplifying this), so they'll want to create a new model that will re-learn again.


Second, It's also about knowledge , and for that, you need to keep acquiring it. Consider the prompt: ""compare the themes in recent books in the Booker Prize shortlist"". I would prefer AI to ""read"" the actual books and provides answers rather than AI that reads a summary or articles about the topic.","ltlrsov"
"ltox2ig","dicemonkey","2024-10-25 14:50:30 UTC","Do you not read ? ‚Ä¶","lto1jmt"
"ltjve3p","v-komodoensis","2024-10-24 18:10:42 UTC","No, AI isn't comparable in any way, shape or form to a human.

AI doesn't get inspired, it just copies.","ltjujtc"
"ltjzpye","Renegadeknight3","2024-10-24 18:32:17 UTC","One of the major differences is scale in data output. A language learning algorithm can ‚Äúread‚Äù hundreds of thousands of books in a few hours. Further, all it can do is replicate patterns. There‚Äôs no greater thought behind whatever work it churns out, and deeper meaning, subtext, and symbolism is by nature accidental and fairly meaningless. It really isn‚Äôt the same","ltjujtc"
"ltjzjvi","walterpeck1","2024-10-24 18:31:26 UTC","> So long as AIs are programmed not to plagiarise

Unfortunately no company is gonna stick to that if they can get away with it.","ltjujtc"
"ltkc9gt","horsetuna","2024-10-24 19:35:01 UTC","The difference is that a human author puts in effort, time, and (hopefully) avoids making their creation too much like anyone else's. 

There's nothing creative about using AI to write a book for you.

And as an author I would rather my writing inspire other writers, not be used by machines to make money.","ltjujtc"
"ltn5e6v","Deleted","2024-10-25 06:08:56 UTC","Lo, they downvoted him because he spoke the truth.","ltjujtc"
"ltkcluu","Exist50","2024-10-24 19:36:45 UTC","> But then, when a human reads a book and later writes a book of their own, haven't they been ""trained"" on that book and all the books they read before in their life? 

Yes, which is why pretty much every legal argument against AI training based on the output has been thrown out.","ltjujtc"
"lto2aj1","hollowtiger21","2024-10-25 11:42:30 UTC","Yeah, that‚Äôs not how people work. 

And you can‚Äôt just press the ‚Äúdon‚Äôt plagiarize,‚Äù button, not when that‚Äôs the whole point.","ltjujtc"
"ltmu9om","Deleted","2024-10-25 04:28:22 UTC","[deleted]","ltkm7cx"
"ltpexmb","John_F_Duffy","2024-10-25 16:22:05 UTC","I started a small press this year called Picket Fire and am already reading submissions of people's manuscripts. Screw the big five.","ltkm7cx"
"ltmpljb","Remnie","2024-10-25 03:51:42 UTC","It‚Äôs great that we live in an age where we can decentralize so much of this stuff.","ltkm7cx"
"ltlftw5","schizophrenicism","2024-10-24 23:06:25 UTC","But my 5 dollar copy of any novel written before 1970, though.","ltjz6b5"
"ltm3xes","ThePrussianGrippe","2024-10-25 01:31:33 UTC","They should be doing that about a lot of businesses.","ltjsg2e"
"ltl8zip","merurunrun","2024-10-24 22:26:00 UTC","Independent creators who think copyright law is there to protect them is like a prisoner showing off their handcuffs as jewelry.","ltkzcr7"
"ltk3d7l","sagevallant","2024-10-24 18:50:34 UTC","An AI to turn all books into audio books? I think Amazon was doing that.","ltjw2dw"
"ltkk57r","GBJI","2024-10-24 20:14:17 UTC","This is going to be a thing. 100%.

Basically, you will train a model on your own tastes, and have this model read all the books with that perspective in mind to reveal to you which ones are going to be your favorites.","ltjw2dw"
"ltkyprh","Much-Ad-5947","2024-10-24 21:28:32 UTC","We already have literature majors who have never read a book cover to cover, I'm doubtful it can get more grim.","ltjw2dw"
"ltmr95m","Beli_Mawrr","2024-10-25 04:04:20 UTC","Chatgpt can you summarize Harry Potter for my kids so they dont have to read it?","ltjw2dw"
"lwygbnd","-The_Blazer-","2024-11-13 18:31:43 UTC","This is roughly what some people are advocating already. The part of art that won't die in this view is making things just for the heck of it, as a hobby exclusively, but of course no one will ever read them, since there will be an infinite amount of free CG work.

A world where artists make art for nobody, and people consume art made by nobody. To me that sounds like a dystopia, but what do I know.","ltjw2dw"
"ltmpqf6","Remnie","2024-10-25 03:52:43 UTC","Sort of a printed version of the Dead Internet Theory?  Grim indeed","ltjw2dw"
"ltjr3c6","IAmThePonch","2024-10-24 17:49:37 UTC","Why make few money when big money do trick","ltjq0dq"
"ltkfi4h","Kalatash","2024-10-24 19:51:09 UTC","I think it's more that the fun, creative work is expensive while the boring, menial work is cheap, so a suit looking to make the most money will try to automate the former first.","ltjq0dq"
"ltlrf8r","hugganao","2024-10-25 00:15:34 UTC",">¬†¬†Because making the AI actually able to do the boring, menial parts costs significantly more and pays significantly less in the short term, so the people doing these think ""why do that when lot of money now?""


This is not how it is AT ALL..... these models are able to do creative parts ""a lot better"" than ""menial"" work because in creative works, there is no ""right"" answer. In other industries, they need these models to have correct outputs. You can't have it output some number that sounds about right but is incorrect when your business depends on the numbers being 100% correct.


In the ""menial work"" industry the money is there. Honestly there is more money there in certain cases. It's just that if the tech does NOT get the output right EXACTLY almostb100% of the times, usually it's considered useless.","ltjq0dq"
"ltl1fk2","Arrowkill","2024-10-24 21:43:07 UTC","It kinda depends on what you mean by the boring stuff. There is plenty of AI that does boring menial tasks, but linking it to something that isn't hyper specialized like a factory arm and making it able to be versatile across various menial boring tasks is fucking hard and expensive. 

It is being worked on, but a lot of the progress talked about happens to be with stuff that was thought to be impossible to replicate. 

In general though, we will have AI that does the boring and the creative stuff and already have many options for both.","ltjq0dq"
"ltnxyh4","Cajum","2024-10-25 11:07:18 UTC","But but I was told the free market always decides the best outcome","ltjq0dq"
"ltlmye4","Lt_General_Fuckery","2024-10-24 23:48:44 UTC","That might be true if AI were gated, and you couldn't like... Run an open source model off your home computer. But the kinds of copyright overreach that big tech and entertainment companies are pushing for would finally be able to put a stop to open source and local AI once and for all.","ltkel4t"
"ltk62s0","sanlin9","2024-10-24 19:04:02 UTC","Have you talked to people working at big tech companies? This is exactly the case. A lot of employees are being pushed really hard to use AI in their job even though it doesn't really work.","ltk0sge"
"ltk9jcp","AvalancheMaster","2024-10-24 19:21:21 UTC","There are things that we can absolutely do with them, but they don't sound nearly as flashy if you are not some type of a relatively niche expert. Data scientist, for example (searching large datasets of interconnected data). Or there are some interesting and promising applications in healthcare, facilitating patient diagnosis. 

The AI techbrats lack any expertise whatsoever ‚Äî other than expertise in bullshitting that they are experts. That's why they focus on pushing the truly stupid stuff. It also helps that they are pulling a grift, and investors who fail for that grift are also likely not people with expertise.

Arguably, a comparison can be made between the current AI hype and the dot-com bubble. A truly promising new technology that's being over-hyped. Doesn't mean it doesn't also solve some very real _real world_ problems.","ltk0sge"
"ltpp2q2","ArchitectofExperienc","2024-10-25 17:13:12 UTC","Whats really frustrating about all of this is that Machine Learning Solutions have existed for decades, and have made some things easier that we now take for granted, like signature recognition for remote check deposits. And, its application in the sciences has done everything from identifying exoplanets, simulating protein folding, and analyzing climate trends from historical records, like ship's logs. 

The problem isn't with the technology, its with the cabal of Venture Capital grifters who see Natural Language Processing and Generative AI as a way to inflate the valuation of their companies, and to play on major corporation's FOMO on new technology. And you're completely right, LLMs don't really have the broad utility that companies like OpenAI claim, but that isn't where they will be making their money. The money is found in licensing data, and licensing access to advanced models, which has the potential to create market conditions where people who, say, write books, which are then used to train models, don't ever see the full financial benefits of their work.","ltk0sge"
"ltkk7x3","ricktor67","2024-10-24 20:14:39 UTC","Its the next blockchain. Just useless in the real world.","ltk0sge"
"ltk1p3n","Sansa_Culotte_","2024-10-24 18:42:14 UTC","> It's because the creatives were too busy being creative and left the money minded to amass. 

I'd argue that the divison of labor and capital is intrinsic to our economic system.

> Creatives need to unionized and those unions need to fight back. It's the only hope of getting things to a better place.

Yup.","ltjp8bv"
"ltklm5l","djinnisequoia","2024-10-24 20:21:35 UTC","No way! Did that really happen? It was supposed to be machine scanning items, and it was just outsourced to cheaper labor overseas?

Edit: never mind, I looked it up. Wow, I had not heard about that. That's hilarious.","ltkeoaz"
"ltl8fqw","MageKessu","2024-10-24 22:22:49 UTC","If you're genuinely curious, [someone on Youtube](https://www.youtube.com/watch?v=zJ6xor2SLNU) has looked into it. Turns out there's at least 1 that was written by an earlier version of chatGPT. If I'm remembering the video correctly, the poems are occasionally intriguing but most are bad.","ltkeoaz"
"ltkfg1a","Exist50","2024-10-24 19:50:51 UTC","> 2 years in what has chatGPT "" published""?

Another way to put this. Look how far it's come in only a couple of years. What happens a decade or two from now? A century?","ltkeoaz"
"ltklsar","Terpomo11","2024-10-24 20:22:26 UTC","Wasn't the first book written by AI published in the 80s, The Policeman's Beard is Half Constructed? It didn't make a lot of sense, of course.","ltkeoaz"
"ltl62hm","Exist50","2024-10-24 22:09:09 UTC","> When the boring, menial parts go wrong, massive lawsuits occur.

This is only an advantage insofar as you have someone to blame and fire. For example, humans are statistically terrible drivers. Even worse if you were to isolate it to certain demographics (e.g. elderly). But an AI just as good as the lower quartile of human drivers, or even the average, is just not politically viable because then what do you do if it does mess up?","ltkyq06"
"ltp1f0y","phyvocawcaw","2024-10-25 15:12:54 UTC","The reason why we still spend so much time doing chores is often because we hold ourselves to a higher standard of living.

We get clothes washers so we buy more clothes to wash. We get cars to commute with so we live farther from work. We get vaccum cleaners so we all expect our houses to be even cleaner. And when these things still save us time we just invent other chores to do.","ltlapfx"
"ltk214n","Sansa_Culotte_","2024-10-24 18:43:52 UTC","> Most boring tasks can be/have been automated already

This is completely, utterly wrong, as any trip to your nearest supermarket should immediately tell you.","ltjyfy5"
"ltjz6zm","walterpeck1","2024-10-24 18:29:39 UTC","""focus on"" does not mean ""it doesn't exist."" You're taking the wrong meaning from their statement.","ltjyfy5"
"ltk5omz","PinkNGold007","2024-10-24 19:02:04 UTC","Leave my creative fun (and hobbies) alone. They're the things that I look forward to. I'm still doing household chores, which wastes my innovative and creative time. And ""no"", my carpet and lawn robots are not sophisticated enough for the rest of the work. Where's my Jetson's life?","ltjyfy5"
"ltk5dke","Deleted","2024-10-24 19:00:32 UTC","[deleted]","ltjyfy5"
"ltk5msm","macemillianwinduarte","2024-10-24 19:01:49 UTC","Haven't seen someone cleaning bathrooms, flipping burgers, or doing roofs lately have you?","ltjyfy5"
"ltkswfz","IndigoBlueBird","2024-10-24 20:58:05 UTC","There is a difference between AI and automation. Like how all squares are rectangles but not all rectangles are squares. But regardless, I don‚Äôt think you‚Äôre really getting at the spirit of my original comment, just the letter","ltjyfy5"
"ltjyxfu","walterpeck1","2024-10-24 18:28:20 UTC","This is about as spurious an argument as mentioning photography or buggy whip makers being put out of business.","ltjwgfq"
"ltkth2w","goodbye-for-now","2024-10-24 21:00:58 UTC","I‚Äôll be honest - it‚Äôs 11 o‚Äôclock at night where I am and while I usually enjoy philosophical debates I‚Äôm too tired for it tonight. To be brief - I don‚Äôt ascribe to the notion that an ability to perform a task is a sole determinant of intelligence.¬† And frankly way smarter and learned people have been having this debate as pertaining to robots and AI for over 70 years. I don‚Äôt think a comment on a Reddit thread is going to come up with a definitive answer.¬†

Edit: 2 main reasons why I don‚Äôt consider LLMs to be intelligent:

1. Their base of knowledge is constrained to data sets used in their training - lack of ability for autonomous learning.

2. Lack or limited capacity for making generalizations when confronted with data differing from training data sets.","ltkgypq"
"ltky804","TonicAndDjinn","2024-10-24 21:25:54 UTC","That's not really true. There's a very real sense in which the model itself is an infringing copy of *many* copyrighted works that your painting is not: it is possible to reconstruct from the model near-exact copies of works it has been trained on. [This paper by Cooper and Grimmelmann](https://arxiv.org/pdf/2404.12590), to be published in the Chicago-Kent Law Review, lays out a nuanced but pretty definitive argument that an AI model *is* a copy of many works it is trained on, in the current sense of copyright law.","ltkbdve"
"ltl7330","Exist50","2024-10-24 22:15:00 UTC","Doesn't always work, because those quotes can pop up elsewhere. E.g. someone posted a few paragraphs from the article in this comment section. You could scrape just the comments here, and still be able to comment on and even quote the source article.","ltl2qth"
"ltl4pe4","omggold","2024-10-24 22:01:19 UTC","Wow this is brilliant","ltkyv3c"
"ltl6tx4","Exist50","2024-10-24 22:13:31 UTC","It's perfectly possible as long as you assume the Times has a consistent, learnable writing style. Which is exactly what major news outlets *try* to have. We know OpenAI's model is far too small to actually contain the training set.","ltkyv3c"
"ltjqbd0","arlondiluthel","2024-10-24 17:45:49 UTC","You... Do know that people can comment without it being a gripe or disagreement, right?","ltjpvnf"
"ltmhrrr","Exist50","2024-10-25 02:58:07 UTC","The model is not *of* the training data; it's derived from it and the training algorithms. And the model contains an infinitesimal amount of any particular work. 

This easily counts as a transformative use case under fair use. Unless you think that should be abolished too?","ltmh1bj"
"lusr43w","HumanID","2024-11-01 02:24:50 UTC","The fact of reality is that humans will continue to exist, thus we will find ways to do things during our 9 to 5. Creatives will still exist, and people will still find ways to pay eachother for art and other works. 

Essentially, as long as humans can continue procreating and existing, we will have creatives. As well, due to needs of existing such as food, housing, etc, humans will by existential need, demand a minimum wage for working any given job. Thus, the jobs will need to change to ensure they supply sufficient payment for employment as well as ensuring sufficient profit per worker to ensure the job exists. If AI threatens components of the job, the job will integrate AI, change, or both, to ensure the equilibrium continues. This dynamic market change is one of humanitys great strengths, ensuring our economy has continued despite enormous changes over the last 120 years. 

I honestly think that our response as humans will be as interesting to watch, if not more, than AI, in response to AI's growth. As, humans won't suddenly die because they cannot write, but rather, will evolve.","ltshhj9"
"ltkchkf","Exist50","2024-10-24 19:36:09 UTC","> AI doesn't get inspired, it just copies.

That is quite simply false, and demonstrates you fundamentally do not understand how these models work. They are literally orders of magnitude too small to hold their training set.","ltjve3p"
"ltjwa9c","atticdoor","2024-10-24 18:15:09 UTC","Man, real-life is turning into a Star Trek episode.","ltjve3p"
"ltkcx9i","Exist50","2024-10-24 19:38:20 UTC","> Further, all it can do is replicate patterns

And you're saying humans can invent entirely new patterns? 

> There‚Äôs no greater thought behind whatever work it churns out, and deeper meaning, subtext, and symbolism is by nature accidental and fairly meaningless

How do you test the meaning?","ltjzpye"
"ltk0obh","atticdoor","2024-10-24 18:37:05 UTC","You are saying that an AI cannot invent, where a human can.","ltjzpye"
"ltkcbi3","Exist50","2024-10-24 19:35:19 UTC","That's not how these models work.","ltjzjvi"
"ltm865t","highkeyvegan","2024-10-25 01:57:35 UTC","I train ai for a living currently, only allowed to use public domain works when training it","ltjzjvi"
"ltlayki","atticdoor","2024-10-24 22:37:40 UTC","Oh I agree, that getting an AI to write books for you isn't creative on the part of the person doing it, but that's not the only reason to give AI books to read.  AI can also give advice, like ChatGPT is used for.","ltkc9gt"
"ltn2nfb","Gamerboy11116","2024-10-25 05:42:13 UTC","‚Ä¶What does this have to do with anything? He‚Äôs asking how A.I is ‚Äòplagiarism‚Äô when comparable things humans do aren‚Äôt considered as such.","ltkc9gt"
"ltl01uz","TonicAndDjinn","2024-10-24 21:35:39 UTC","I encourage you to read [this paper by Cooper and Grimmelmann](https://arxiv.org/pdf/2404.12590), to be published in the Chicago-Kent Law Review. To summarize: if a model outputs data it was trained on (near) verbatim, that demonstrates that the model itself is a copy (in the sense of copyright law) of those parts of its training data.","ltkcluu"
"ltox21a","atticdoor","2024-10-25 14:50:26 UTC","There *is* a way to program an AI to avoid plagiarising- tell it that no more than N words in a row should be the same as a set of words found in it's training corpus.¬†¬†


Sure, you would need to get a human to double-check it before releasing anything officially generated that way, but then work by humans needs to be double-checked for plagiarism too.¬†¬†","lto2aj1"
"ltn7146","sikonat","2024-10-25 06:25:29 UTC","But what are the guarantees Amazon aka KU which demands exclusivity aren‚Äôt or won‚Äôt do the same?","ltmu9om"
"ltrpw10","AplogeticBaboon","2024-10-25 23:53:14 UTC","Do you take kids' picture books?","ltpexmb"
"ltno86z","banana_assassin","2024-10-25 09:32:49 UTC","That is so rubbish for the hardworking voice actors out there who can put so much into a great reading of an audiobook. It's going to become so rare because the people cost more to hire than an AI.","ltk3d7l"
"ltkypkw","10ebbor10","2024-10-24 21:28:31 UTC","It's already been a thing.

https://www.business-standard.com/world-news/ai-tools-fake-songs-and-10m-fraud-us-musician-indicted-for-royalty-scam-124090600274_1.html

Guy doing it got arrested for fraud.","ltkk57r"
"ltkwywi","Censing","2024-10-24 21:19:15 UTC","Honestly this doesn't sound so bad. I've read so many books over the years and I often end up feeling I didn't get anything out of the experience. I find it so hard to find things I'll actually enjoy, and lord knows the algorithm on Amazon has never recomended me anything good. I find it so hard to find good books, but my only trusted method is relying on word-of-mouth.","ltkk57r"
"ltpaqqd","ECEXCURSION","2024-10-25 16:00:23 UTC","Yep","ltmpqf6"
"ltk1kb4","Sansa_Culotte_","2024-10-24 18:41:33 UTC","number must go up","ltjr3c6"
"ltk55j2","sosleepy","2024-10-24 18:59:24 UTC","It's my cash and I want it now! 877-CASHNOW!","ltjr3c6"
"ltkikn1","Twokindsofpeople","2024-10-24 20:06:26 UTC","It's not that expensive.  Most authors don't make a living off their books.  Most artists are not rich.  Conversely most garbage men make pretty good money with good benefits.  

It's that it is easier to automate creative labor it turns out. Although the menial jobs won't last long either lots of humanoid robots in the pipeline that are made to plug and play human roles in places like warehouses.","ltkfi4h"
"ltlaqfj","WhimsicalWyvern","2024-10-24 22:36:19 UTC","Trust me, AI engineers have been working on the boring stuff too. Just... no one minds.

For example, software engineers use chatgpt all the time to generate basic scripts, and loads of people use it to generate basic emails / forms as a starter.

Chatgpt and the like is basically a really hard working, but also really dumb intern. They'll do really tedious research for you and save you time if you use them right, but you can't trust them to do a good job or do complicated things.

There's also stuff like cleaning up large messy databases, company specific help tools, oodles and oodles of predictive algorithms.

And then there's hard stuff that involves machine vision, like driverless cars, which do work... most of the time.

If you think it's just art that's getting automated, you're not paying attention.","ltkfi4h"
"ltkjup0","CotyledonTomen","2024-10-24 20:12:50 UTC","No, theres just a lot of art and written material they can steal. Its harder to teach an AI the subjective rules of accounting or how to create accounting books, even if an invoice or reciept wasn't generated perfectly. A lot of that stuff is proprietory or doesnt have step by step instructions for how it was generated. You cant just show an AI year end statements and textbooks for it to become an accountant. They can steal other peoples creativity, but its harder to steal their practical professional knowledge that exists outside of easily acquired materials.","ltkfi4h"
"ltmhcgt","Street_Roof_7915","2024-10-25 02:55:21 UTC","They dont make anything. They repackage, scrape, and spew.","ltlrf8r"
"ltoslg4","Deleted","2024-10-25 14:27:00 UTC","[deleted]","ltl1fk2"
"ltkgo3s","delirium_red","2024-10-24 19:56:55 UTC","It's great for some things. I use it daily as a personal assistant - it's really great for summarizing and querying tenders, RFP's, legal documents, requirements and such. It's also a great assistant for coding - you can get scaffolding done really quickly. So menial stuff that saves time.

But the flood of terrible AI content on the internet, bots and books.. it's not worth it.","ltk62s0"
"ltkbyzt","Exist50","2024-10-24 19:33:34 UTC","> Arguably, a comparison can be made between the current AI hype and the dot-com bubble

This is my preferred analogy as well. We're in the exploratory phase, so there's going to be a lot of inflated claims and grift, but at the same time, the underlying technology is very real and important. I don't think anyone can truthfully claim to know how things will pan out in a decade or two.","ltk9jcp"
"ltlmkp7","Fantastic-Newt-9844","2024-10-24 23:46:29 UTC","The blockchain technology itself is revolutionary


Things that use it are hit or miss¬†","ltkk7x3"
"ltkslu3","RealisticSolution757","2024-10-24 20:56:37 UTC","Yeah man loads of 'high tech' shit is like this it's unbelievable üòÇüòÇ","ltklm5l"
"ltkg1oe","RealisticSolution757","2024-10-24 19:53:50 UTC","There are a lot of questions that need to be answered first before this stuff can get much better. Right now it's down to chip making. I suspect they'll get somewhat better, I use Claude Opus/4o (or whatever the newest) at work, and honestly they're stagnating or if anything sometimes declining.","ltkfg1a"
"ltpn200","Comprehensive-Fun47","2024-10-25 17:03:00 UTC","Why do you say humans are statistically terrible drivers?

I think humans are pretty excellent at using the skills required by driving. I mean generally, we are able to judge distances and spaces, and coordinate our movements around other vehicles and objects. It's a complex task we are able to accomplish very well, when we are paying attention and have had enough practice to learn the required skills.","ltl62hm"
"ltlrovv","lost_send_berries","2024-10-25 00:17:09 UTC","Didn't 90% of people once work in the industry of agriculture? Now all that food comes from just 3% of the workforce. And a lot of machinery.","ltk214n"
"ltkggnr","Exist50","2024-10-24 19:55:53 UTC","There's plenty of focus on boring tasks, but it's advertised to those specific fields, not the general public. Pretty much every customer service line is using or investigating AI, for a simple example.","ltjz6zm"
"ltkf9yl","Exist50","2024-10-24 19:50:00 UTC","> Leave my creative fun (and hobbies) alone. They're the things that I look forward to

No AI is going to stop you from writing for your own fun. Though overzealous ""anti-AI"" copyright law might.","ltk5omz"
"ltkxux4","Boxy310","2024-10-24 21:23:58 UTC","Hell, even just a robot to pick strawberries would revolutionize agriculture.","ltk5dke"
"ltl1soz","mjfgates","2024-10-24 21:45:06 UTC","Roofs actually have an interesting automation thing going on-- they're using quadcopter drones with cameras to do detailed inspections without having to send somebody up, it is SO much faster/cheaper/safer-- but of course that's not ""AI,"" because it works.","ltk5msm"
"ltkana4","Exist50","2024-10-24 19:26:55 UTC","> This is about as spurious an argument as mentioning photography

You say that as if the same arguments against AI weren't used against photography, recorded media, etc.","ltjyxfu"
"ltk3sf8","sawbladex","2024-10-24 18:52:38 UTC","Photography almost certainly ate some of the marketshare realistic portraits, but because it took forever for color photos to become cheap and good, it is hard to detect and suppose a ""what if"" for the technology not existing.

How can you measure the impact of a civil war technology on the market that was already fairly niche and only for the wealthy, took like 50 years to become mass market?

Digital images have already made art production cheap and easy to spread enough that it become no longer the option only rich people could get.","ltjyxfu"
"ltkxs3q","Exist50","2024-10-24 21:23:33 UTC","> I don‚Äôt ascribe to the notion that an ability to perform a task is a sole determinant of intelligence

The main problem here is that for the term to have any practical meaning, we need some output-based way of testing it. Otherwise it's akin to magic.","ltkth2w"
"ltn2njt","Snowball_Furball","2024-10-25 05:42:15 UTC",">I don‚Äôt think a comment on a Reddit thread is going to come up with a definitive answer.¬†

I don't have a personal definition either, but to be fair to u/Exist50, you claimed that LLMs are not intelligent, which to me implies you had some definition of intelligence in mind.","ltkth2w"
"ltn0zrb","Gamerboy11116","2024-10-25 05:26:40 UTC","You can‚Äôt just assert that these things ‚Äòare definitely not intelligent‚Äô unless you‚Äôre both willing and able to provide an actual definition for what ‚Äòintelligence‚Äô even means.","ltkth2w"
"ltl2994","Exist50","2024-10-24 21:47:35 UTC","> There's a very real sense in which the model itself is an infringing copy of many copyrighted works that your painting is not

Copyright law is defined on an output. No reasonable person would claim the model itself resembles the source material, so you have to instead argue that the outputs are inherently a violation, regardless of the lack of resemblance to any particular piece of training data. 

> This paper by Cooper and Grimmelmann, to be published in the Chicago-Kent Law Review, lays out a nuanced but pretty definitive argument that an AI model is a copy of many works it is trained on, in the current sense of copyright law.

So far, at least, this argument has done extremely poorly in court. More to the point, since copyright law makes no distinction between a human brain and a computer, could you not use the same arguments against human artists? Just as when an AI is exposed to a work many times they're able to reproduce it better, so too do humans. I think many people would be able to recite a few lines from a famous book, or perhaps sketch an approximation of a famous painting from memory alone. 

And this is the dangerous part that Doctorow starts to touch on. You let this arguments stand, and you've essentially back-doored a massive extension of copyright law that can and will be used against human authors. Think about how many famous books have spawned new trends of very clearly derivative works. Do you think the publisher of the ""original"" won't try to pull the same argument to claim ownership?","ltky804"
"ltl4jj8","omggold","2024-10-24 22:00:24 UTC","A perfect example of this is a recent post in r/chatgpt where people are attempting to use ChatGPT to generate a completely full glass of wine. It‚Äôs almost impossible. And that‚Äôs because it was clearly only trained on images of glasses of wine that are typically half full and never filled to the brim and the AI does not inherently understand the distinct components required to illustrate a full wine glass on its own. I feel like this example shows on constrained AI is to its inputs and if those inputs are your art, then the likelihood of an output being an almost exact replication are high.","ltky804"
"ltngtip","TonicAndDjinn","2024-10-25 08:10:53 UTC","Are you going to claim that the Times's style is so predictable that chatgpt was able to correctly predict the name of the person they interviewed later in the article?

The model doesn't contain the entire training set. It does encode portions of the training set.","ltl6tx4"
"ltjqihw","Deleted","2024-10-24 17:46:48 UTC","[deleted]","ltjqbd0"
"ltmjq4w","dodgyville","2024-10-25 03:10:33 UTC","It's a dataset of weightings trained on the artefacts.

Also saying it ""easily counts [as] fair use"" doesn't make it true btw, rather wishful thinking.","ltmhrrr"
"ltke6p7","v-komodoensis","2024-10-24 19:44:35 UTC","Can you define the word ""Inspiration"" for me? Because I'm talking about the relationship of a human being with it's environment and how it leads to art. 

I understand that AI doesn't just literally copy and paste stuff, but that's not my point.","ltkchkf"
"ltjxjlt","DeathByLeshens","2024-10-24 18:21:29 UTC","No, you just think AI is something it isn't. When talking computer science, an AI is any data set system that can present a solution based on input. That means that calculators with preset variables is an AI. AI is really nothing more than a marketing term that does not relate to the sci-fi presentation of AI.","ltjwa9c"
"ltq3ltr","Gamerboy11116","2024-10-25 18:26:35 UTC","I get it.","ltjwa9c"
"ltllu31","Renegadeknight3","2024-10-24 23:42:07 UTC",">and you‚Äôre saying humans can invent entirely new patterns

Well, considering humans invented the languages themselves I‚Äôm going to go with yes, obviously they can. 

I don‚Äôt need to test meaning. By nature it cannot have intention. It isn‚Äôt thinking. If you dance in front of a mirror, your reflection isn‚Äôt dancing with intention. It copies as a function, but there is no meaning coming from the mirror. If an algorithm compiled every dance known to man on a screen, and animated a person dancing based on the next most likely move (which is what language models do at a simplified level, predict the next most likely word), the dance it would come up with is meaningless, an assortment of moves based solely on probability, not intention","ltkcx9i"
"ltk2s4q","Renegadeknight3","2024-10-24 18:47:38 UTC","No, I‚Äôm saying an AI cannot make artwork with intention, where a human can

And in a practical, non-philosophical level, it will only be used to cut out authors who already have to struggle in an ultra-competitive industry so the corporations can make money. It‚Äôs anti-society on every level from a publishing perspective","ltk0obh"
"ltkcy3k","walterpeck1","2024-10-24 19:38:26 UTC","I wasn't talking about how the models work, unless you want to try and argue the hilariously incorrect idea that AI art isn't stealing from existing art.","ltkcbi3"
"ltmbxrk","walterpeck1","2024-10-25 02:21:08 UTC","Hey, glad to hear it.","ltm865t"
"ltllc2u","horsetuna","2024-10-24 23:39:07 UTC","Good points, although there's few ways to actually enforce rules that say 'They can use it to conclude/explain book passages only' etcetera.  I mean, we've seen attempts at banning certain adult websites, attempting to block regional sharing of youtube, and pirating in general and there's always ways around it. OTOH if someone is pirating my books to READ, I'm more okay with that than pirating them to train AI to write books.

  
I do like AI being used for medical purposes and such like that. That's the AI type that helped win a Nobel Prize after all (not the AI itself of course).

  
OTOH, someone can probably just make their own AI to skim books and do that without needing an 'official' one I suppose if we want to go all the way.","ltlayki"
"ltn42xf","horsetuna","2024-10-25 05:55:55 UTC","I'm explaining why one is fine and the other is plagiarism","ltn2nfb"
"ltl2uj8","Exist50","2024-10-24 21:50:55 UTC","I replied to you elsewhere, so I'll link that to keep discussion consolidated: https://www.reddit.com/r/books/comments/1gb7yis/penguin_random_house_ai_and_writers_rights_you/ltl2994/

But to summarize:

> if a model outputs data it was trained on (near) verbatim, that demonstrates that the model itself is a copy (in the sense of copyright law) of those parts of its training data

If this argument holds, then you can just as well call the human brain itself a copyright violation, which has disastrous implications for independent creators. The law has no provision in copyright law for whether the source is human or machine. 

We should be very glad that, thus far, the courts have **not** agreed with this line of reasoning, and hope they continue not to do so.","ltl01uz"
"ltm1rzj","Bakoro","2024-10-25 01:18:22 UTC","What is being argued, is that building an artificial mind should itself be illegal, and that no artificial mind should have memories of its own experience.   
      
What's being argued is that we should simply halt whole branches of scientific and technological advancement.   
   
I'd rather abandon copyright law if people are demanding that it be an ultimatum.","ltl01uz"
"ltn4hkd","Gamerboy11116","2024-10-25 05:59:55 UTC","That‚Äôs absurd. Things can output other things without necessarily having those things physically stored within them‚Ä¶ that‚Äôs the difference between ‚Äòencoding/decoding‚Äô and ‚Äòcompression/decompression‚Äô, and, well‚Ä¶ ‚Äògeneration‚Äô.","ltl01uz"
"ltpaaik","Deleted","2024-10-25 15:58:06 UTC","[deleted]","ltn7146"
"ltqrejs","Deleted","2024-10-25 20:30:34 UTC","""Demands exclusivity"" is a bit misleading. Amazon may try to lock you in for three months but they don't have the legal authority to demand a permanent noncompete agreement. Once those 90 days of exclusive sales are up, you can do what you want. Unless something has changed recently, that is. 

As for training AI models on our work, of course they will. Frankly, I expect that all of these tech giants will do exactly as they please until governments step in and force them to stop. That's just kind of the nature of big business. As long as corporations exist, they will do whatever they can to increase their profits. What I can say is there's a credible argument to be made that using a tool to scrub the internet for content violates copyright law in the same way that using a program to collect people's personal identification amounts to identity theft.","ltn7146"
"ltu4l9i","John_F_Duffy","2024-10-26 11:46:56 UTC","No. Sorry. It's all literary fiction.","ltrpw10"
"ltple53","archwaykitten","2024-10-25 16:54:39 UTC","I'm not worried about this.  New audiobook narrations aren't competing with AI audiobook narrations.  They're competing with movies, tv shows, video games, youtube, the millions of books that have already been written, etc.  It just doesn't make sense to skimp.

If anything, I'm worried publishers are going too far in the *other* direction, paying more to hire celebrity narrators for their name recognition rather than spending less money on professional narrators who do this full time.","ltno86z"
"ltl5hiw","jiggjuggj0gg","2024-10-24 22:05:46 UTC","Sure, if you want some airport book purely for cheap entertainment.¬†

The joy of literature comes from seeing the world from another human being‚Äôs perspective and sharing that experience with other readers who all have their own point of view on the same text.¬†

We already have a problem with echo chambers, the last thing we need is limitless AI rubbish tailor made to never challenge anyone‚Äôs point of view on anything ever.¬†","ltkwywi"
"ltkyuo5","GBJI","2024-10-24 21:29:16 UTC","In my mind, this doesn't sound bad at all. I want this.","ltkwywi"
"ltl4cq5","chris8535","2024-10-24 21:59:20 UTC","Time is a form of expense. The time ratio reduction here is insane¬†","ltkikn1"
"ltl10q1","erikkustrife","2024-10-24 21:40:51 UTC","Artist is a generally safe job where you most likely won't be killed. Meanwhile garbage man is the 7th In the top ten most dangerous jobs in america.","ltkikn1"
"ltkzh8h","MorgothTheDarkElder","2024-10-24 21:32:35 UTC","it's also about the fact that ai is terrible at reliably producing consistent work. it matters less if ur art program will always create new images and never twice the same thing or if u can't produce the same image twice but with a specific detail changed from one to the other, if u aren't producing for something that requires such a level of consistency.  
most boring jobs require a specific level of consistency, the opposite of creativity. if u want to automate that, AI of the LLM or image ""remix"" variety is not rly suitable for that. boring algorithmic automation is still the way to go there but that is far more expensive as u usually have to create custom solutions for most scenarios that cover all edge cases and can't just use a one size fits all solution","ltkjup0"
"ltnsa83","LathropWolf","2024-10-25 10:14:56 UTC","No different then a human when you break it down...

Go on vacation in the mountains during winter and open your cabin window to a snow scene with deer and get moved to paint it? Whoops, Thomas Kinkade already did that (as have others...)

""There is nothing new under the sun""

AI is a Tool, and any tool can be used for good or bad. Folks whined about printing presses taking jobs way back when, and here we are today","ltmhcgt"
"lttavti","Arrowkill","2024-10-26 06:43:38 UTC","So when I said AI that does boring stuff, I did not explicitly mean machine learning. You are right that those models do exist, but I mostly meant that we already image to text algorithms, algorithms to handle menial work tasks, etc. 

AI already does a lot and it continues to advance, just more quietly than the machine learning advancements.","ltoslg4"
"ltkledn","CotyledonTomen","2024-10-24 20:20:30 UTC","There are a lot of instances of AI misrepresenting or just straight-up lying about difficult material. I wouldn't trust an AI to find legal information for me. Legal code is a language all its own, couched in a specific context. If an AI is learning from *the internet*, that means uncountable erroneous legal interpretations by laymen that refuse to learn the lagnuage. Just look at any soverign citizens' interpretation of law. 

If all it's doing is searching a word and telling you where it is, that's fine, but Word's been doing that for decades.","ltkgo3s"
"ltkw6i8","sanlin9","2024-10-24 21:15:06 UTC","I find it is only good at cursory things and needs careful direction. So much careful direction that half the time the same keywords in any search engine would get me the same answer.

Mostly though think top commenter described it well given what I'm hearing about the internals at tech companies: a solution in search of a problem. 

The fact that hallucinations are so common and people keep thinking its good for legal documents is mind boggling though.","ltkgo3s"
"ltmey7e","Deleted","2024-10-25 02:40:11 UTC","[deleted]","ltlmkp7"
"ltkgr2q","Exist50","2024-10-24 19:57:20 UTC","We certainly need more (and more efficient) compute, but that seems to be one problem we've been very good at solving historically.","ltkg1oe"
"ltl11zk","mjfgates","2024-10-24 21:41:02 UTC","Moore's law died ten years ago. So, not happening.","ltkg1oe"
"ltl7ek1","Exist50","2024-10-24 22:16:51 UTC","> but of course that's not ""AI,"" because it works

Or rather, if it works, people try to find excuses for why it doesn't count as AI.","ltl1soz"
"ltpnzdo","Comprehensive-Fun47","2024-10-25 17:07:41 UTC","I think the difference is photography can't eventually take on a life of its own. When photography was invented, there was no sense that cameras would eventually become sentient. They would always be operated by humans.

AI is essentially different from other techno logical advances because there will be a tipping point where humans are not in control of it anymore. Once the AI is making the decisions, we may regret inventing it, in a way we'd never regret inventing photography or recorded music.","ltkana4"
"ltkchjz","walterpeck1","2024-10-24 19:36:09 UTC","That in no way disproves what I said, which is that it's a terrible argument to make.

Photography did not replace painting. It created a new medium. Audio recordings didn't kill live vocal performances of all kinds, if anything it popularized them even more. Print spread knowledge and fiction to the masses; it didn't replace handwriting or calligraphy. 

AI art seeks to *replace* and *mimic* humans which sets it apart from those other medias you mentioned. It's a massive escalation of abilities that takes humans out of the process... which those other medias did not do and even if they did, it was at a far smaller scale.

More than any of that, AI art steals. It steals other people's work, both jobs and the content they create. Artists from top to bottom understand this, and it's the entire focus of the very article we're commenting on. 

NO one wants AI art except corporations looking to save money and AI bros that think it makes them real artists (it doesn't). 

AI belongs in the boring stuff, the dangerous stuff, not in art. And anyone that supports AI art does not support art and is immediately suspect to me.","ltkana4"
"ltnfedp","CC-5576-05","2024-10-25 07:55:09 UTC","Intelligence is a pretty well defined word 

From Cambridge dictionary:     
 ""the ability to learn, understand, and make judgments or have opinions that are based on reason""     

From Miriam Webster:      
1. the ability to learn or understand or to deal with new or trying situations : reason also : the skilled use of reason
2. the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests)
3. the act of understanding : comprehension
4. the ability to perform computer functions     

LLMs dont meet either of these definitions, they can't learn independently, they can't reason, can't deal with new situations. They can only really pass tests that have been part of its training data, it can absolutely not think abstractly. It doesn't understand anything it just generates the most probable next word. It can't compute things that aren't in it's training data.","ltn0zrb"
"ltqz19z","Deleted","2024-10-25 21:11:53 UTC","Well it seems this runs close to Citizens United in a sense, then. The fundamental weakness in this line of reasoning is how do you define personhood. SCOTUS has extended the definition of a person to include businesses, in particular corporations, but as this is concerned, that becomes a double edged sword if AI is not given similar status. If the model being trained on your work is considered a tool, them it's not really any different than a word processor as far as the law is concerned. If you use a word processor to plagiarize someone's work or multiple person's works in your own, or even your own work in some cases, you are liable for it. 

It seems to me that using copyrighted work to train an AI model to shunt out works derivative of that copyrighted work isn't any different. Because the AI is still a tool and not a person, leaving the person who is using the tool liable for any infringements the tool commits on their behalf.","ltl2994"
"ltng5ek","TonicAndDjinn","2024-10-25 08:03:30 UTC","> If this argument holds, then you can just as well call the human brain itself a copyright violation, which has disastrous implications for independent creators. The law has no provision in copyright law for whether the source is human or machine.

One point is the distinction between copy and violating copy; how the thing is used matters to the law. I'd guess (but IANAL!) that one could argue in court that the human brain is in a legal sense copies of several copyrighted works, but not infringing copies.

If you assume for the sake of argument that we have an AGI running around, its model considered as data on a disc would be more analogous to a brain scan than a brain. If you sell copies of your brain scan together with a computer program that extracts auditory memories of songs, that probably would count as copyright infringement, especially if you streamlined the whole process so that the buyer doesn't need to know anything about brains to listen to the music. (Reflecting on everything I've written, I think this is the most interesting hypothetical.)

> Copyright law is defined on an output. No reasonable person would claim the model itself resembles the source material, so you have to instead argue that the outputs are inherently a violation, regardless of the lack of resemblance to any particular piece of training data.

No, resemblance in a superficial sense doesn't matter. A down-sampled JPEG thumbnail of a photograph is still a copy, legally speaking, even if it's just a bunch of 0s and 1s (or really, a bunch of excited and not excited semiconductors). What matters is if you can produce a reasonably accurate representation of the original thing. So being able to prompt the model to output near-verbatim pieces of its training data is evidence that that training data is still encoded within the parameters of the model.

> So far, at least, this argument has done extremely poorly in court. More to the point, since copyright law makes no distinction between a human brain and a computer, could you not use the same arguments against human artists? Just as when an AI is exposed to a work many times they're able to reproduce it better, so too do humans. I think many people would be able to recite a few lines from a famous book, or perhaps sketch an approximation of a famous painting from memory alone.

Yeah! My brain has a low-fidelity copy of The Wheel of Time in it. That's not, in itself, a violation of copyright law.

> And this is the dangerous part that Doctorow starts to touch on. You let this arguments stand, and you've essentially back-doored a massive extension of copyright law that can and will be used against human authors. Think about how many famous books have spawned new trends of very clearly derivative works. Do you think the publisher of the ""original"" won't try to pull the same argument to claim ownership?

I don't think this follows. This argument is not an extension of copyright, it follows from principles which are well-established already: the models are a bunch of data on a hard drive, and you can use that data to read copyrighted works. Hence the model is a copy.

There's a separate important question about whether the model parameters are an infringing copy. I tend to come down on the side that they are, but that's a whole extra argument. For now, I'm just trying to establish that they are, indeed, a copy.","ltl2994"
"lwyh1gp","-The_Blazer-","2024-11-13 18:35:18 UTC","Maybe we should start making a difference between computers and humans, given that they are not, in fact, the same thing, and that the whole point of copyright is to allow people to make more art.

This is an example of a copyright extension that would benefit small creatives far more than doing nothing, since small creatives are not computers.

We should be careful about extending copyright mindlessly like we did for Disney, but this doesn't mean copyright cannot be reformed. Hell we might even be able to sneak in a reduction in total protection time in exchange for stronger protections from data use, that would be nice for a change.","ltl2994"
"ltl7nvh","carolinallday17","2024-10-24 22:18:21 UTC",">I think many people would be able to recite a few lines from a famous book, or perhaps sketch an approximation of a famous painting from memory alone. 

Yes, and if they tried to sell those lines as poetry or that sketch as original art, we'd all know that it was bullshit. Moreover, your second point betrays a fundamental misunderstanding of what it is to interact with media.","ltl2994"
"ltlxnfl","orangejake","2024-10-25 00:53:19 UTC",">¬†Copyright law is defined on an output. No reasonable person would claim the model itself resembles the source material, so you have to instead argue that the outputs are inherently a violation, regardless of the lack of resemblance to any particular piece of training data.

This seems like a weak argument. One can make the same argument about compressed files. Moreover, this perspective (‚ÄúAI as compression‚Äù) is a mildly popular perspective among experts.¬†","ltl2994"
"ltl834h","Exist50","2024-10-24 22:20:48 UTC","This isn't strictly unique to AI though. You see how some Renaissance painters depicted women? Michelangelo's looked like male body builders with the world's worst boobjob. Intellectually, he surely would have been able to describe differences, but depicting it in art proved oddly difficult.","ltl4jj8"
"ltnijfj","Exist50","2024-10-25 08:30:01 UTC","> The model doesn't contain the entire training set. It does encode portions of the training set.

If the encoded portion is so small it cannot meaningfully be equated to the original, then that too is permitted under copyright law. Especially in the context of news, where you can copyright neither facts nor style. At best, you can use that as evidence, but not necessarily proof, that certain material was used in the training set. I say ""not proof"" because information is available from more than just first parties. Case in point, someone training an AI on this subreddit would have also scraped quotes from this article, even if it was not explicitly included. 

We know for a fact that the model itself is orders of magnitude smaller than the training set. It's unreasonable to believe a substantial portion of any particular piece of training material survives that process intact, and certainly it is not designed to do so. You need something relatively small and strongly represented (e.g. Bible quotes or memes) to reliably survive that process, and even that isn't reliable. No sane person could be expected to use these AI models to explicitly reproduce copyrighted work.","ltngtip"
"ltk2x9a","Sansa_Culotte_","2024-10-24 18:48:20 UTC","> Sure, but if that wasn't your intention then you used some odd phrasing

Is your gripe here that you agree with them?","ltjqihw"
"ltjssme","arlondiluthel","2024-10-24 17:57:57 UTC","*shrug*","ltjqihw"
"ltmlm0j","Exist50","2024-10-25 03:23:02 UTC","> It's a dataset of weightings trained on the artefacts.

Yes, and? There's nowhere in those weights you can just find the training set.

> Also saying it ""easily counts [as] fair use"" doesn't make it true btw, rather wishful thinking.

Every court thus far has ruled that it is. It meets every requirement without any real room for argument.","ltmjq4w"
"ltn33kc","Gamerboy11116","2024-10-25 05:46:28 UTC","You literally just said ‚Äòit just copies‚Äô‚Ä¶ which is wrong. Matter of fact, there isn‚Äôt _any_ part of these models which ‚Äòcopies‚Äô‚Ä¶ well, _anything._

And I think it‚Äôs pretty telling that you argue ‚ÄòA.I is different from human beings because it can‚Äôt get inspired‚Äô and then define ‚Äòinspiration‚Äô as ‚Äòsomething that only human beings can do‚Äô. 

You‚Äôre deliberately defining these things to explicitly exclude A.I‚Ä¶ at that point, all you‚Äôre doing is saying ‚ÄòA.I is different because A.I is different‚Äô.","ltke6p7"
"ltkhixa","Exist50","2024-10-24 20:01:09 UTC","I think of inspiration as being exposed to *something* external that you either directly or indirectly incorporate in your own work. I think anyone would be hard pressed to meaningfully define that term in a way unique to humans.","ltke6p7"
"ltkcqm5","Exist50","2024-10-24 19:37:24 UTC","> an AI is any data set system that can present a solution based on input

What do you think your brain does? It's inputs, current state, and outputs.","ltjxjlt"
"ltlmg19","Exist50","2024-10-24 23:45:44 UTC",">Well, considering humans invented the languages themselves

So is your assertion that an AI can't invent language?

>I don‚Äôt need to test meaning. By nature it cannot have intention. It isn‚Äôt thinking

This is circular reasoning. Or at best, an admittance that you can't actually define the criteria you claim exists. 

>If you dance in front of a mirror, your reflection isn‚Äôt dancing with intention. It copies as a function, but there is no meaning coming from the mirror.

An AI model isn't a mirror. 

>the dance it would come up with is meaningless, an assortment of moves based solely on probability, not intention

And yet, back in the real world, we know AI is capable of producing cohesive works.","ltllu31"
"ltk39az","atticdoor","2024-10-24 18:50:02 UTC","Define ""intention"".","ltk2s4q"
"ltkdzrz","Exist50","2024-10-24 19:43:38 UTC","> I wasn't talking about how the models work

How these models work is quite key to the question of plagiarism. 

> and argue the hilariously incorrect idea that AI art isn't stealing from existing art

It isn't by any reasonable definition. Which is why those claims have been thrown out of court.","ltkcy3k"
"ltn47uk","Gamerboy11116","2024-10-25 05:57:15 UTC","AI art isn‚Äôt stealing from any existing art.

Matter of fact, considering these models can run locally, and take up only a few gigabytes in file size, and work without being connected to the Internet‚Ä¶ trying to claim that is basically saying these models violate entropy. Because you simply can‚Äôt store that much information within that little information.

Like‚Ä¶ how do you think these things work, exactly‚Ä¶?","ltkcy3k"
"ltmf4n6","highkeyvegan","2024-10-25 02:41:18 UTC","Me too! I had an interaction with an author on TikTok about that earlier and she basically told me to go fuck myself, won‚Äôt be buying her books üò≠","ltmbxrk"
"ltn4lf7","Gamerboy11116","2024-10-25 06:00:58 UTC","‚Ä¶No, you‚Äôre not. Just because using AI to write a story isn‚Äôt ‚Äôcreative‚Äô doesn‚Äôt mean it‚Äôs plagiarism.","ltn42xf"
"ltndl5z","TonicAndDjinn","2024-10-25 07:35:03 UTC","Ah, sorry, I wasn't reading usernames and didn't notice I was replying to the same person both times. I'll respond there.","ltl2uj8"
"ltngmih","TonicAndDjinn","2024-10-25 08:08:44 UTC","No, what's being argued is that a model is a copy. They very deliberately make no arguments about what ""should"" be legal.

Beyond that, it seems pretty reasonable to me that any artificial mind should not be privately owned; from a moral point of view I'm much more willing to let all the copyright stuff go if no one is profiting off of it.

But we're also as far from artificial minds today as we were fifty years ago. The current question is about current AGI, which does copy.","ltm1rzj"
"ltnc4xq","TonicAndDjinn","2024-10-25 07:19:07 UTC","Did you read the article?","ltn4hkd"
"ltrgt5s","elmonoenano","2024-10-25 22:56:17 UTC","Joe Biel actually talks a lot about Amazon. He doesn't use them at all anymore. A lot of terms of having your books on Amazon prevent you from discussing their strategies, and he was wary of a lawsuit, but I got the impression that they charge the publishers at every step. It seems like they even charge you to put your results in search results, even if your book is what was searched for. Apparently any time someone just types your book into amazon's search bar, it's money out the publisher's pocket.

B/c of stuff like that he's been very happy away from Amazon and seen a lot of growth for Microcosm.","ltpaaik"
"ltuj9ae","AplogeticBaboon","2024-10-26 13:31:51 UTC","Appreciate the answer. More than I've gotten from literally everyone I've submitted to. Any connections? I have it written and rough illustrated, but I need an illustrator and publisher. I can't even draw stick figures.","ltu4l9i"
"ltqsg3g","Deleted","2024-10-25 20:36:12 UTC","I might be in the minority, but I prefer the small timers. Their narration tends to have more heart in it, and I find myself better anle to get into the story when I don't know who the narrator is.","ltple53"
"ltorzyr","Deleted","2024-10-25 14:23:45 UTC","[deleted]","ltkyuo5"
"ltoct9x","Bantersmith","2024-10-25 12:55:30 UTC","> Meanwhile garbage man is the 7th In the top ten most dangerous jobs in america.

Really? That's fascinating. Ive always respected the people who maintain society's infrastructure, especially the messy jobs other people would turn their noses at (I work as a healthcare assistant, so sorta similar vibe there!), but I would never have considered rubbish collection as a *dangerous* job. 

Do you know why that's the case?","ltl10q1"
"ltkz80c","ONEAlucard","2024-10-24 21:31:13 UTC","The problem with standard word searching is that you need to know the exact word to search for.

An issue i have at my work is I have technical manuals hundreds of pages each, in a company that we change what we call things every 2 minutes. So AI has in fact helped me find things significantly faster due to being able to use the spirit of an idea rather than an exact phrase. It has saved me hours and hours in that regard.","ltkledn"
"ltls2el","WTFwhatthehell","2024-10-25 00:19:25 UTC","depends what you're trying to do and how you do it.

""needle in a haystack"" type problems ""is there anything in this document relevant to X"" is something they're quite good at because that's something they're tested on during training.

got a big document and want to know what it says in relation to bicycle use on a sunday? hallucinations aren't much of a problem because it's directing you to specific text in a given document.","ltkw6i8"
"ltmhxfl","Fantastic-Newt-9844","2024-10-25 02:59:09 UTC","Saying blockchain is just useless misses the real innovations and benefits it's bringing to various industries.¬†


For example, Walmart started using blockchain to improve their supply chain. With IBM's Food Trust blockchain, they can track where their produce comes from in seconds instead of days. Lavazza coffee is another example. This helps make food safer and cuts down on waste. Maersk and IBM made TradeLens, a blockchain system that digitizes shipping records. This makes global trade more efficient and reduces fraud.


About the energy concerns: not all blockchains use a lot of power. Bitcoin's Proof of Work system does use a lot of energy, but other blockchains use more efficient methods like Proof of Stake or Proof of History Ethereum switched to Proof of Stake, cutting its energy use by over 99%. Also, abstraction layers (L2+) like the Lightning Network let us handle transactions off-chain, which uses less energy.¬†


That being said, Bitcoin miners, through their ability to dynamically adjust energy concumption, can even help stabilize the power grid. Miners can adjust how much energy they use based on the current load. They can use extra energy when demand is low and cut back when it's high. Power plants operate most efficiently at known, sustained loads.¬†


There's also companies like Crusoe Energy who take natural gas that would be wasted and use it to power Bitcoin mining, turning waste into value. In places like Iceland and Washington State, miners use renewable energy like geothermal and hydroelectric power, which supports green energy development.


By turning electricity directly into money, Bitcoin mining encourages finding cheaper and cleaner energy sources. This creates opportunities and supports the growth of renewable energy projects.","ltmey7e"
"ltki6l1","RealisticSolution757","2024-10-24 20:04:29 UTC","Times change. I'm too high to get into the technical details (too stupid anyway) but it's at a point where investors are asking when are they gonna see returns, and frankly the delta between what was promised and what has been therefore invested versus what we got in terms of productivity increases is huge.","ltkgr2q"
"ltl5qpa","Exist50","2024-10-24 22:07:14 UTC","There are other ways. These really parallel circuits make good targets for low-voltage targetted improvements. And memory is a huge part of the picture.","ltl11zk"
"ltkf3b1","Exist50","2024-10-24 19:49:05 UTC","> Photography did not replace painting

But in many markets, it did. What does the market for portraits look like now vs then? 

> Audio recordings didn't kill live vocal performances of all kinds, if anything it popularized them even more

At the time, the claim was precisely that recorded music is ""soulless"", and killing live performances. 

> Print spread knowledge and fiction to the masses; it didn't replace handwriting or calligraphy.

At scale, it did. It turned handwriting from a necessity for literature into a novelty. Scribes (as in the olden days) aren't really a thing anymore. 

> More than any of that, AI art steals

Not by any sane definition of the term, no. You don't seem to understand how these models work if you claim they're just stealing. That, or you're saying the same of human artists?

> NO one wants AI art except corporations looking to save money

So if no one wants it, let the free market decide. Should be easy.","ltkchjz"
"ltnqme8","Gamerboy11116","2024-10-25 09:58:11 UTC","> ‚Äúthe ability to learn, understand, and make judgments or have opinions that are based on reason‚Äù

LLMs can do all this.

> the ability to learn or understand or to deal with new or trying situations : reason also : the skilled use of reason

LLMs can do all this, as well.

> the ability to apply knowledge to manipulate one‚Äôs environment or to think abstractly as measured by objective criteria (such as tests)

‚Ä¶All this, too.

> the act of understanding : comprehension

Depends on your definition of ‚Äòunderstand‚Äô. I‚Äôd argue they do, but‚Ä¶ whatever.

> the ability to perform computer functions

lol‚Ä¶ I guess we can safely say LLMs _are_ intelligent, then‚Ä¶ huh? Thanks for clarifying!

> LLMs dont meet either of these definitions

What the fuck.

They meet literally every single one of them.

> they can‚Äôt learn independently,

‚Ä¶Where did you get this from? Why are we talking about them being ‚Äòindependent‚Äô? That‚Äôs not part of the definitions you provided.

> they can‚Äôt reason, 

????????????????

‚Ä¶This is probably the worst take I‚Äôve ever heard about LLMs. What do you even mean it ‚Äòcan‚Äôt reason‚Äô? How else is it able to answer questions‚Ä¶ at all? 

It can‚Äôt just be casually finding the exact answer to whatever hyper-specific question you asked online! It works offline, first off- and these models can be run locally, all while only taking up a few gigabytes of space.

Like‚Ä¶ when I ask it for incredibly specific and tailored responses to a very specific question with over a dozen unique factors specific to this very specific situation‚Ä¶ and it _nails_ it in less the  half a _second‚Ä¶_ where do you think it‚Äôs getting that from? 

I‚Äôm actually baffled. How can you unironically believe this? Like‚Ä¶ what does this even _mean?_

> can‚Äôt deal with new situations

Well, I like to test that from time to time, by giving it memes that I‚Äôve made‚Ä¶ brand new ones, never seen before. Then, I ask it to try and dissect the meme, and explain the joke, and why it‚Äôs funny. It works almost every time.

> They can only really pass tests that have been part of its training data, 

‚Ä¶You mean besides all the tests they can pass that weren‚Äôt part of their training data, right‚Ä¶?

> it can absolutely not think abstractly

[Stop lying.](https://chatgpt.com/share/671b6442-edac-800c-8b26-1559265a5d45)

> It doesn‚Äôt understand anything it just generates the most probable next word.

I watched a video of a guy who spent several _months_ trying to program an advanced black hole scatter plot simulator thing‚Ä¶ you know, for his _iob,_ before finally finishing it. Then, he asked ChatGPT-o1 to try and do it‚Ä¶ and after a few responses of finagling it‚Ä¶ it fucking _worked._

> It can‚Äôt compute things that aren‚Äôt in it‚Äôs training data.

I watched a video of a guy trying to program with this thing. He kept telling ChatGPT what to do, but the code just wasn‚Äôt working. Eventually, he traced down the issue to the fact that not only was ChatGPT‚Äôs knowledge cut-off before a crucial update to the language, _the programming language‚Äôs documentation was wrong._ So, he provided ChatGPT with the original documentation, explained what was _wrong_ with it‚Ä¶ and ChatGPT just went ‚Äòoh ok lol‚Äô and _immediately_ fixed the problem.

Why are you just straight-up lying to me‚Ä¶? Like, there isn‚Äôt even an excuse to be this categorically wrong. You‚Äôre not even trying to be honest here.","ltnfedp"
"ltnicg3","Exist50","2024-10-25 08:27:50 UTC","> I'd guess (but IANAL!) that one could argue in court that the human brain is in a legal sense copies of several copyrighted works, but not infringing copies.

How would that not also be infringement *if* one is to argue that their mere presence is itself a copyright violation? 

> What matters is if you can produce a reasonably accurate representation of the original thing. So being able to prompt the model to output near-verbatim pieces of its training data is evidence that that training data is still encoded within the parameters of the model

There are two aspects of this. First is the question addressed above - whether the model's imperfect ""memory"" is sufficient in and of itself to be considered a copyright violation, irrespective of usage. 

The other is about reproduction. In general, AI models are *not* capable of reproducing any meaningful amount of their training data. The ""compression ratio"", if that's how you want to think of it, is simply too large. You could know for a fact that it's trained on, say, The Wheel of Time, but if you go and ask ChatGPT or whatever model you want, it's not going to spit out anything you could reasonably call a reproduction of a full book. You'd be lucky to faithfully reproduce a single paragraph. The even weaker argument, that I see still pop up, is that being trained on certain works inherently makes any output a derivative for the purpose of copyright law, which has predictably proven to be the weakest legal argument so far.","ltng5ek"
"lwyhscl","Exist50","2024-11-13 18:39:04 UTC",">and that the whole point of copyright is to allow people to make more art

Copyright makes it harder for an individual to make art, not easier. Copyright exists to make art more *profitable*. And if you think it's small creatives that will benefit from huge extensions of copyright law, you are sorely mistaken.","lwyh1gp"
"ltl8eyz","Exist50","2024-10-24 22:22:42 UTC","> Yes, and if they tried to sell those lines as poetry or that sketch as original art, we'd all know that it was bullshit

But that's not what the argument in question is. You're saying the ""brain"" that *produced* the work is, itself, a violation. That's an extremely important difference. Selling a drawing of Mickey Mouse might be unambiguously illegal, but merely being *capable* of doing so? 

> Moreover, your second point betrays a fundamental misunderstanding of what it is to interact with media.

Elaborate then...","ltl7nvh"
"ltm0ybh","Exist50","2024-10-25 01:13:21 UTC","> One can make the same argument about compressed files

How so? The entire point of file compression is you can use it as a 1:1 equivalent for the original in most scenarios. E.g. the difference between a jpeg and RAW file typically makes little to no visible difference. 

But that's not how these AI models work. I can ask a model to summarize a work, and maybe it can even quote snippets from it. But no reasonable person can claim the output to be a substitute for the complete original. If I asked ChatGPT to generate for me, say, the Harry Potter books, even if it wasn't handicapped, nothing it could produce can be said to equate to the original.","ltlxnfl"
"ltpoyty","Comprehensive-Fun47","2024-10-25 17:12:40 UTC","A better example might be Michelangelo trying to depict Jonah and the whale. He had never seen a whale in his life.

Check out how he painted a whale: https://commons.m.wikimedia.org/wiki/File:Prophet_Jonah.jpg#mw-jump-to-license","ltl834h"
"lto1vwc","omggold","2024-10-25 11:39:20 UTC","Sure but the renaissance was 600 years ago. And Michealangelo wasn‚Äôt mass producing copies of art work he copied from someone he he trained his painting style on without credit. Likely a terrible analogy, but AI isn‚Äôt just some artist learning a new technique its software mass fed the creation of thousands of people without consent and replicated with little transformation or originality.","ltl834h"
"ltrmoiq","TonicAndDjinn","2024-10-25 23:32:57 UTC","For the moment, I'm just trying to argue that it is a copy; if we don't agree about what things are copies, we certainly won't find agreement about whether or not there's infringement.

> At best, you can use that as evidence, but not necessarily proof, that certain material was used in the training set. I say ""not proof"" because information is available from more than just first parties. Case in point, someone training an AI on this subreddit would have also scraped quotes from this article, even if it was not explicitly included.

Well, I mean, there's an issue about causality for if you're claiming chatgpt memorized its quotes from this conversation. ;) But it doesn't matter where openai got their training data from. If the Times's article is in there, it's in there.

> We know for a fact that the model itself is orders of magnitude smaller than the training set. It's unreasonable to believe a substantial portion of any particular piece of training material survives that process intact, and certainly it is not designed to do so. You need something relatively small and strongly represented (e.g. Bible quotes or memes) to reliably survive that process, and even that isn't reliable. No sane person could be expected to use these AI models to explicitly reproduce copyrighted work.

And yet, the Times was able to generate quotes from their articles, multiple paragraphs long, consistently. If you want to claim that substantial portions of the articles are not encoded in the model, you need a more compelling explanation of how its able to do that.

I agree their fidelity is often pretty bad, and if you didn't already know the training data you were looking for it would be challenging to know when you've found it. That's probably one of the stronger arguments why the model shouldn't be considered an *infringing* copy. But a black box that 999,999 times out of 1,000,000 prints ""Reply hazy, try again"" and with a 1 in 1,000,000 chance prints the complete text of Snow Crash is still a copy of Snow Crash, even if it's not a very useful one. An encrypted copy of the Cryptonomicon is still a copy of the Cryptonomicon, even if I don't tell you the private key, although it would be pretty hard to prove in court.

(Well, probably. If it's encrypted with public key algorithm where you can verify directly whether or not a key is correct I think the ciphertext alone would count as a copy. If you encrypt it with a one-time pad, it might be the case that each of the ciphertext and the key is equally a copy, as long as both exist somewhere, but if either is destroyed the other ceases to be a copy? There are weird implications here. In particular, whether or not something is a copy is not supposed to change over time unless the thing itself changes.)","ltnijfj"
"ltr5oge","dodgyville","2024-10-25 21:49:21 UTC","Don't get swindled by a company promising you a bridge they don't own.","ltmlm0j"
"lto0foq","v-komodoensis","2024-10-25 11:27:47 UTC","I've literally said I understand that it doesn't just copy, it was figure of speech to make a simple point. Please don't forget the context of my first reply, which the commenter compared the process of a human being creating something to the way a language model replicates and outputs information. 

And yes, I am deliberately defining things to exclude AI because it is not comparable to a human being. Any human feeling or expression will naturally exclude AI in any discussion. 

I honestly don't understand where you getting at, do you think I'm being unfair to the technology or that I don't understand it? 

I'd rather die than read a book ""created"" by AI.","ltn33kc"
"ltksepn","djinnisequoia","2024-10-24 20:55:37 UTC","I'm not who you were replying to; but I would say that your definition of inspiration is accurate insofar as inspiration takes part in suggesting a means or flavor of expressive output, like ""I want to paint something that makes me feel the way that painting does,"" or ""I want to write a poem using that same clever rhyming scheme.""

However, imo this is separate from *intent* with respect to meaning. AI given a specific prompt is certainly not fundamentally different from what is happening when a human is inspired. 

But I'm pretty sure that AI cannot yet *intend* to produce a work which will levy associated human meaning in an intuitive way to make an unspoken meaningful statement. Which is not to say that it can't do it by accident. 

I don't think you can tell a generative AI to produce a work that does what *Guernica* does, but on a different topic. Like, it knows the definition of ""ironic,"" ""poignant"" and ""referential,"" but would it know how to produce the *effect* of the *meaning* of those things?","ltkhixa"
"ltkeulm","DeathByLeshens","2024-10-24 19:47:52 UTC","No, the human brain is far more complicated than this. The whole point of sapience is that you as a human can make useful and accurate judgments and intuitive thoughts. No computer in existence can do this.","ltkcqm5"
"ltlmzul","Renegadeknight3","2024-10-24 23:48:58 UTC","If an AI ‚Äúinvents‚Äù a language it will be based on the patterns of linguistics that humans already do. Human language evolved on its own through human biology and thought processes. Any ‚Äúai‚Äù languages are going to be scraping data from linguistics, inherently copying naturally occurring human methodologies. They really aren‚Äôt the same

>an ai model isn‚Äôt a mirror

It‚Äôs called an analogy. 

I‚Äôm not talking about whether or not it‚Äôs cohesive. I‚Äôm talking about whether or not there is *intent* behind it.

It isn‚Äôt ‚Äúcircular‚Äù reasoning to say an ai model is incapable of intent. Something needs to be sapient to have intention. My argument that it isn‚Äôt *thinking* is the argument, it‚Äôs not circular. Unless you‚Äôre trying to argue that language learning models are sapient, which they may well be one day but certainly aren‚Äôt now","ltlmg19"
"ltn4110","Gamerboy11116","2024-10-25 05:55:25 UTC","It‚Äôs always so sad seeing genuinely good questions like this get downvoted.","ltk39az"
"ltn50n0","horsetuna","2024-10-25 06:05:09 UTC","Yes I am","ltn4lf7"
"ltnmkz4","Gamerboy11116","2024-10-25 09:14:48 UTC","‚Ä¶Given that it‚Äôs 63 pages long, I haven‚Äôt yet, sorry. I‚Äôll get around to it soon though, it looks interesting. But I disagree with your summary on principle, so I‚Äôm hoping you just misrepresented that article‚Äôs conclusion somewhat, because otherwise I feel it‚Äôs going to be a very frustrating read.","ltnc4xq"
"ltulrr0","John_F_Duffy","2024-10-26 13:48:00 UTC","If you don't illustrate, you need to hire someone. I'd look at Reedsy or Fiverr.","ltuj9ae"
"ltpycfe","GBJI","2024-10-25 17:59:48 UTC","I used to be a librarian, a very long time ago. And then a bookseller. Nothing fancy, mind you.

I am 100% sure personal AI models will be better than I ever have been at recommending books that I never read myself.

I am also 100% convinced that it will be much much better than current recommandation algorithms based on statistics taken from user data at large.

Anyways, you don't have to believe me, and I completely understand your reservations. I had pretty much the same before I started working with this tech.","ltorzyr"
"ltoo0m3","gel_ink","2024-10-25 14:01:44 UTC","Same reason that delivery truck drivers have the 6th most dangerous job... it's the time spent on the road.","ltoct9x"
"ltoebkb","erikkustrife","2024-10-25 13:05:01 UTC","from what i understand its the people that work at the facilities rather than the ones that do pick up. However i have watched the training videos for pickup and that seems kinda dangerous.","ltoct9x"
"ltl1kni","CotyledonTomen","2024-10-24 21:43:53 UTC","Wait, so youve fed the manuals into the AI? Because i havent come across an AI that just scans pdf's or doc images on a computer as if it were a word file.","ltkz80c"
"ltmrc0a","Deleted","2024-10-25 04:04:57 UTC","[deleted]","ltmhxfl"
"ltkkjd3","Exist50","2024-10-24 20:16:15 UTC","Oh trust me, I work in the tech industry, and I know exactly what you mean. I think everyone who's not just in it for the grift understands that something is going to have to give. But I don't think that means we're going to see advancement just stop. More likely, companies stop scaling up compute to such an extreme degree, and everyone whose business model is ""ChatGPT wrapper for X"" at a billion dollar valuation goes out of business. 

Last I heard even Nvidia was hesitant about demand holding through the end of this year, much less next.","ltki6l1"
"ltkh850","Theotther","2024-10-24 19:59:40 UTC","> But in many markets, it did. What does the market for portraits look like now vs then?

Still massive among the wealthy, like it's always been.

> At the time, the claim was precisely that recorded music is ""soulless"", and killing live performances.

Source?  Soulless perhaps, but that argument is a lot easier to make when the thing that makes it literally has no soul.

> At scale, it did. It turned handwriting from a necessity for literature into a novelty. Scribes (as in the olden days) aren't really a thing anymore.

Computer's did that more.  Handwriting and cursive was a fundamental skill until as recently as the 90s.  

Your last 2 comments are pure tech bro bullshit.","ltkf3b1"
"ltkfsje","walterpeck1","2024-10-24 19:52:35 UTC",">  let the free market decide

Yeah that always works! That ol' free market is always right, and corporations never abuse that ever.

The only thing the unassailable free market will do is allow corporations to make more money at the expense of creators. Individuals will barely ever take advantage. It's literally happening right now.

Here's a few parting rhetorical questions for you. What is the *point* of AI art if not to replace people, which is what it is doing? What value does it add, that traditional mediums both physical or digital don't already do?

If you want AI generated slop don't let me stop you, because I can't. I'll just continue to enjoy art made by people, and will support the vast majority of artists that agree with that.","ltkf3b1"
"ltnstma","CC-5576-05","2024-10-25 10:20:19 UTC","Lol you're like that Google engineer that thought some llm was sentient because it said so. You don't seem to understand how these things work. It doesn't understand anything it doesn't reason it's just a very advanced probability function to generate words. 

Have you ever tried to give it any mathematical or logical reasoning problem? You have to tippy toe around the maths because it just can't do it, and then it will still hallucinate completely made up shit and when you call it out on it it'll say it's sorry and come up with some other bullshit. 

There was a recent [whitepaper by apple](https://machinelearning.apple.com/research/gsm-symbolic) that showed that llms perform very well in maths reasoning... Because it was trained on the standard benchmark questions. And when you change these questions a bit while staying in the same difficulty level they just crap the bed.

Sure it's pretty good at coding but that's because it's been trained on all of GitHub and stackoverflow among others. And even then it causes more problems than it solves for anything that's a bit complicated.","ltnqme8"
"ltrq7mg","TonicAndDjinn","2024-10-25 23:55:18 UTC","> > I'd guess (but IANAL!) that one could argue in court that the human brain is in a legal sense copies of several copyrighted works, but not infringing copies.
> 
> How would that not also be infringement if one is to argue that their mere presence is itself a copyright violation?

I mean, the chatgpt models are being used primarily for profit; commercial profit is not the primary use of your brain (I hope). That kind of distinction matters. The existence of the information in the model makes it a copy; the details of how it was constructed and what it's used for probably make it infringement.

Although having done a little more looking-stuff-up-online, I'm not sure that a court would hold that a human brain is a copy, because copies need to be ""material objects ... fixed by any method now known or later developed...""; I think perhaps human memory is not fixed in the sense of the law. So, brain scans probably are copies; brains maybe(?) legally aren't.

I think the more reasonable stance is that brains should be copies, but we grant special exceptions to conscious beings to memorize stuff. If we get a real AGI, I'll be happy to not call its memory an infringement, just like it probably deserves rights of self-determination and equal protections under the law and so on. But that sure isn't what chatgpt is.

> The other is about reproduction. In general, AI models are not capable of reproducing any meaningful amount of their training data. The ""compression ratio"", if that's how you want to think of it, is simply too large. You could know for a fact that it's trained on, say, The Wheel of Time, but if you go and ask ChatGPT or whatever model you want, it's not going to spit out anything you could reasonably call a reproduction of a full book. You'd be lucky to faithfully reproduce a single paragraph. The even weaker argument, that I see still pop up, is that being trained on certain works inherently makes any output a derivative for the purpose of copyright law, which has predictably proven to be the weakest legal argument so far.

Except, they are. They do frequently, sometimes when you prompt them with the first half of an article and sometimes when you ask them to repeat the word ""poem"" forever. The Times repeatedly coerced chatgpt into printing quotes several paragraphs long. Not all training data has been equally compressed, and a whole lot of it is still in there with high fidelity.

The fact that chatgpt spits out memorized articles from the New York Times is evidence that they're encoded in the weights. But something can be encoded in the weights even if you can't figure out a prompt to display it. If there is any algorithm which -- given the model -- can recover part of the training data, then that part has been memorized.","ltnicg3"
"lwyijrd","-The_Blazer-","2024-11-13 18:42:51 UTC","Given that we still live in a world where people need money to survive, making art profitable helps people make more art than having absolutely no copyright at all. If you want to argue against all copyright that's fine, but in that case AI is entirely irrelevant since those concerns are related to copyright as it exists IRL. Ireland has a pilot program of a kind of UBI for artists, for an example of an alternative (this would cost enormously more money).

Besides, I don't think making a distinction between physical persons and computers is an especially 'huge' extension of copyright law.","lwyhscl"
"ltl9woa","carolinallday17","2024-10-24 22:31:26 UTC","I find there to be something particularly odious about an argument that reduces the human brain and human interaction to a simple amalgamation of the things a human has consumed, whereas the model you're defending is definitionally just that. I'm not really interested in a defense from legislation or court opinions; I simply feel that we are deserving of better than that kind of blatant misanthropy. And given that this misanthropy seems to be the only thing animating your comments in this thread, I'm not really interested in continuing this conversation.","ltl8eyz"
"ltpptpp","Exist50","2024-10-25 17:16:59 UTC","> Sure but the renaissance was 600 years ago

And? Humans aren't fundamentally any different. 

> And Michealangelo wasn‚Äôt mass producing copies of art work he copied from someone he he trained his painting style on without credit

Do you know how Renaissance artists learned? Often by studying/copying old Greek and Roman statues. Doubt anyone asked them...","lto1vwc"
"ltrojx8","Exist50","2024-10-25 23:44:46 UTC","> And yet, the Times was able to generate quotes from their articles, multiple paragraphs long, consistently

Were they, or did they cherry pick examples (of varying length and generality) for their case? As stated, we know the models are way smaller than their training data, and that they are not even designed to preserve it. If you could reliably reproduce arbitrary training data from the model, that implies the creation of a frankly miraculous compression algorithm. I don't think anyone involved believes that's an accurate description of these models. And that's most likely something OpenAI et al can convincingly argue in court.","ltrmoiq"
"ltq3jj9","Gamerboy11116","2024-10-25 18:26:16 UTC","> And yes, I am deliberately defining things to exclude AI because it is not comparable to a human being. Any human feeling or expression will naturally exclude AI in any discussion.

Yeah. Exactly. That‚Äôs the problem.

If you‚Äôre deliberately defining things to explicitly exclude AI, then saying ‚Äòwell, AI can‚Äôt do this!‚Äô as a _counterpoint_ to literally _any claim_ that AI is‚Ä¶ anything other than an exact carbon copy of a human being, is absurd. It doesn‚Äôt _mean_ anything at that point‚Ä¶ all you‚Äôre saying is ‚Äòit‚Äôs not  human!‚Äô and like, sure, yeah. 

But that doesn‚Äôt mean it couldn‚Äôt possess some specific characteristics that are similar to what we human beings do.

> I‚Äôd rather die than read a book ‚Äúcreated‚Äù by AI.

I‚Äôm not sure why you put ‚Äòcreated‚Äô in quotes here. It literally does create a _new_ book‚Ä¶ all it gleans from its training is the abstract concepts, and what they _mean_ on a fundamental level.

And regardless‚Ä¶ I‚Äôm pretty sure this is called, uh‚Ä¶ bias.","lto0foq"
"ltkg0qm","Exist50","2024-10-24 19:53:42 UTC","> No, the human brain is far more complicated than this

What, specifically, do you claim the human brain does that isn't captured by inputs, current state, and output? 

> The whole point of sapience is that you as a human can make useful and accurate judgments and intuitive thoughts

Then define how you claim to test for this. Because humans have notoriously terribly judgement, and computers can certainly make judgements as well. And what is an ""intuitive thought""?","ltkeulm"
"ltn3az1","Gamerboy11116","2024-10-25 05:48:26 UTC","‚Ä¶What? Computers make useful and accurate judgements all the time‚Ä¶ we rely on them for missile guidance systems, for instance. They seem to work just fine there. And what do you define as ‚Äòintuition‚Äô?","ltkeulm"
"ltltglv","Exist50","2024-10-25 00:27:52 UTC",">Human language evolved on its own through human biology and thought processes.

So you might consider this biological training...?

>It‚Äôs called an analogy. 

An analogy needs to be, well, analogous...

>I‚Äôm not talking about whether or not it‚Äôs cohesive. I‚Äôm talking about whether or not there is intent behind it.

You were saying that an AI model basically just returns an average regardless of the context, but we know that simply isn't the case. 

>It isn‚Äôt ‚Äúcircular‚Äù reasoning to say an ai model is incapable of intent.

When your argument is that an AI isn't capable of intent because it's not capable of intent, then yeah, that's circular reasoning. So I'll ask explicitly. How do you test whether something has intent?","ltlmzul"
"ltn3pik","Gamerboy11116","2024-10-25 05:52:20 UTC","Modern AI is able to solve questions it was never trained off of. It‚Äôs _clearly_ capable of coming up with new stuff in _that_ sense.","ltlmzul"
"ltnlca9","Gamerboy11116","2024-10-25 09:00:55 UTC","‚Ä¶Well, address my point, then.","ltn50n0"
"ltodkyh","TonicAndDjinn","2024-10-25 13:00:20 UTC","I found it well-written and worth the read.

The point is that as far as copyright law is concerned, for something to be a copy there just needs to be a way -- even theoretical -- of getting a representation of the thing from it. The fact that LLMs frequently produce long passages of copyrighted text faithfully and frequently implies that the information to reproduce those passages has been encoded in the weights of the model itself. The fact that one method of extracting these passages is to ""generate"" responses to prompts doesn't matter; the difference between encoding, compression, and generation is a technical one, not a legal one.

Suppose I train a neural net exclusively on Wuthering Heights. In response to prompts, it has a very large chance to print paragraphs from Wuthering Heights. Would you grant that the weights of this model are a copy of the work?","ltnmkz4"
"ltq9be5","Deleted","2024-10-25 18:55:52 UTC","[deleted]","ltpycfe"
"ltofmjx","Bantersmith","2024-10-25 13:13:04 UTC","That makes a lot of sense! I could imagine some of the machines/compactors etc they work with must be fairly gnarly on an industrial scale. 


Yeah, Im sure pick-up comes with its own risks too to be fair (off the top of my head...hopping on and off the back of the truck in and around roads/traffic, early morning with low visibility, etc). 

Edit: in fact, Im reminded of a fairly grim accident that happened in my city a few decades ago. Someone took a nasty spill into the back of a rubbish collection truck and was crushed by the machinery. From what I remember, it was at least quick for the poor person involved, but it was apparently a horrific sight. My friend was only 16 at the time, and she happened to be standing only about a dozen feet away when it happened. She went to a LOT of therapy for the trauma.","ltoebkb"
"ltlr088","WTFwhatthehell","2024-10-25 00:13:03 UTC","I've been doing this with chatgpt ever since they allowed document uploads.

200 page user manual for some weird stats library?

""I'm trying to do X. Please look at this manual and tell me what functions are likely to be useful""

10 seconds later it's got the info I need.

These bots are very bad at ""please off the top of your head give me a well cited set of info about X"". 

They're very good at ""needle in a haystack"" type problems where you give them a large document or set of documents and you're looking for them to extract specific relevant info for you. partly because ""needle in a haystack"" problems are easily tested for during training.","ltl1kni"
"ltl3t8y","ONEAlucard","2024-10-24 21:56:18 UTC","Yeah my work has partnered with Microsoft and integrated copilot into our systems now. So it has gone over all our emails, chat, and documents. It‚Äôs pretty great","ltl1kni"
"ltl45vx","_Tagman","2024-10-24 21:58:16 UTC","working with laaarge quantities of text is actually the only thing that Google's model is state-of-the-art at (Gemini 1.5).

https://www.kaggle.com/competitions/gemini-long-context

Since Google is more interested than others in search applications, I think they have focused on this aspect more as well as RAG.

""Retrieval-augmented generation (RAG) is a framework that combines generative large language models (LLMs) with information retrieval systems to improve the quality of AI response""","ltl1kni"
"ltmxwdu","Fantastic-Newt-9844","2024-10-25 04:58:48 UTC","I appreciate the conversation, and I'm not trying to sell you anything (I promise!)‚Äîjust sharing my thoughts.¬†


- **Supply Chain Management**: Walmart uses blockchain to track the origin of its produce. This system lets them trace products in seconds instead of days, improving food safety and reducing waste. [Source](https://www.ibm.com/case-studies/walmart-food-safety-blockchain)


- **Shipping and Logistics**: Maersk and IBM developed **TradeLens**, a blockchain platform that digitizes shipping records, making global trade more efficient and reducing fraud. [Source](https://www.tradelens.com/)


- **Finance**: JPMorgan created **Quorum**, a blockchain platform to streamline interbank payments securely. [Source](https://www.jpmorgan.com/solutions/cib/news/quorum-blockchain) Decentralized Finance (**DeFi**) platforms like **Compound** and **Aave** use smart contracts to enable lending and borrowing without intermediaries, lowering costs and increasing accessibility. [Compound Source](https://compound.finance/) | [Aave Source](https://aave.com/)


- **Insurance**: Companies like **AXA** use smart contracts for flight delay insurance. If a flight is delayed, the smart contract automatically triggers a payout to the customer, eliminating manual processing. [Source](https://www.axa.com/en/magazine/fizzy-blockchain-flight-delay-insurance)


- **Real Estate**: Platforms like **Propy** use blockchain to simplify property transactions. Buyers and sellers can complete deals securely and transparently without traditional middlemen, reducing closing times and fees. [Source](https://propy.com/)


- **Healthcare**: Blockchain is used to securely store and share medical records, ensuring patient data is tamper-proof and only accessible to authorized parties. Companies like **Medicalchain** are working on this. [Source](https://medicalchain.com/)


- **Insurance Example**: In the insurance industry, smart contracts can automate claims processing. For instance, **Etherisc** offers decentralized insurance for flight delays and crop damage, streamlining payouts without manual intervention. [Source](https://etherisc.com/)


- **Supply Chain Example**: **De Beers** uses blockchain and smart contracts to track diamonds from mine to retail, ensuring authenticity and ethical sourcing. [Source](https://www.debeersgroup.com/sustainability-and-ethics/blockchain)


Regarding energy consumption, a significant portion of Bitcoin mining now uses renewable energy. In Texas, miners are working with energy companies to stabilize the grid by adjusting their energy usage based on supply and demand. [Source](https://www.cnbc.com/2021/08/14/bitcoin-miners-are-giving-new-life-to-old-fossil-fuel-power-plants.html) El Salvador is even using geothermal energy from volcanoes to power Bitcoin mining, tapping into a renewable resource. [Source](https://www.reuters.com/technology/el-salvador-looks-power-bitcoin-city-with-volcanoes-2021-11-21/)


- **Corporate Adoption**: Companies like **Microsoft**, **Overstock**, and **AT&T** accept Bitcoin as payment. [Microsoft Source](https://www.microsoft.com/en-us/store/b/bitcoin) | [Overstock Source](https://www.overstock.com/bitcoin) | [AT&T Source](https://about.att.com/story/2019/att_bitpay.html)


- **National Adoption**: Countries like **El Salvador** and the **Central African Republic** have made Bitcoin legal tender, allowing people to use it for everyday transactions. [El Salvador Source](https://www.bbc.com/news/world-latin-america-57398274) | [Central African Republic Source](https://www.reuters.com/technology/central-african-republic-adopts-bitcoin-an-official-currency-2022-04-27/)


In places with unstable currencies or high inflation, people use Bitcoin to store value and make transactions, providing financial services to those without access to traditional banking. Cryptocurrencies also make remittances easier, enabling faster and cheaper cross-border money transfers compared to traditional methods. [Source](https://www.worldbank.org/en/news/feature/2018/12/19/remittance-fees-world-remittance-prices-global-database)


Regarding turning electricity into money: no - the economy isn't the same thing. I can literally run a program on a computer and be rewarded with what can be converted to money. In the economy, I need to produce something.¬†


Hopefully these sources and extra information provides some extra insight¬†","ltmrc0a"
"ltkqkx6","RealisticSolution757","2024-10-24 20:46:27 UTC","And after companies invested billions in AI in house or third party, they'll demand that productivity to made up for by workers, fun shit for us lol","ltkkjd3"
"ltkje4t","Exist50","2024-10-24 20:10:31 UTC","> Still massive among the wealthy, like it's always been.

Not really. It's not entirely gone, but when's the last time you've heard of anyone that's not a head of state or similar commission a portrait? It's certainly not the default way to capture an event anymore. 

> Source? Soulless perhaps, but that argument is a lot easier to make when the thing that makes it literally has no soul.

Here're some great examples from the 1930s: https://www.smithsonianmag.com/history/musicians-wage-war-against-evil-robots-92702721/

The rhetoric is nearly identical. 

> Computer's did that more. Handwriting and cursive was a fundamental skill until as recently as the 90s.

For one-off personal notes and such, yes. No one was hand-writing entire books at any scale. Literally just copying books by hand used to be a full-time job before the printing press. 

> Your last 2 comments are pure tech bro bullshit.

Lmao, you keep saying people don't want it... then keep trying to argue that people shouldn't be allowed to use it.","ltkh850"
"ltkg83o","Exist50","2024-10-24 19:54:42 UTC","You were the one claiming people don't actually want it. So yeah, then let people decide. 

> and corporations never abuse that ever

You seem to be very much in favor of corporations dictating what you can and cannot do with a book.","ltkfsje"
"ltptnak","Gamerboy11116","2024-10-25 17:36:09 UTC","> Lol you‚Äôre like that Google engineer that thought some llm was sentient because it said so.

The fact that you think pointing out the things that modern LLMs are capable of would be _impossible_ if they worked like you say they do is somehow comparable with‚Ä¶ believing these things are sentient, is‚Ä¶ strange.

> You don‚Äôt seem to understand how these things work.

_You_ don‚Äôt seem to understand how these things work. You‚Äôre acting like sentience is somehow required for _understanding‚Ä¶_ which I‚Äôm assuming you don‚Äôt believe, because otherwise that would mean you must‚Äôve been _nothing but dishonest._

Think about it. If sentience is _required_ for _understanding‚Ä¶_ then saying LLMs don‚Äôt have understanding as an _argument_ against their _capabilities,_ is just arguing ‚Äòwell, they‚Äôre not sentient‚Äô. And if that‚Äôs your only argument‚Ä¶ I think I‚Äôve made my point.

I‚Äôm operating on the assumption that ‚Äòunderstanding‚Äô is capable of being achieved without sentience‚Ä¶ which _necessarily implies_ it can be achieved with pure math, because math is just an extension of logic, and logic is just an extension of _consistency,_ and the universe can only logically be either deterministic or random (unless you propose some very strange way in which things can _matter_ while simultaneously being undetectable and therefore irrelevant), and if it‚Äôs deterministic all things must be _consistent_ while pure randomness would break not just our entire understanding of reality, but in fact, our entire capacity to _ever_ understand it‚Ä¶ which, for the sake of argument and intuition, I‚Äôm going to be assuming isn‚Äôt _true._ Because otherwise, there would be no point in having this discussion at _all._

> It doesn‚Äôt understand anything it doesn‚Äôt reason it‚Äôs just a very advanced probability function to generate words.

Why is that not compatible with understanding? And if it truly _isn‚Äôt‚Ä¶_ then why do you believe this concept of ‚Äòunderstanding‚Äô is somehow important? How do you know we _humans_ have it, beyond just defining it in such a way to explicitly include us and explicitly exclude LLMs?

> Have you ever tried to give it any mathematical or logical reasoning problem? 

Yes. It usually blows it out of the water‚Ä¶ less so with math, but that makes sense. I mean‚Ä¶ why are you even asking this? [I already gave you an example of it obviously using reasoning and abstract thinking skills...](https://chatgpt.com/share/671b6442-edac-800c-8b26-1559265a5d45) one that you haven‚Äôt addressed.

Matter of fact, you haven‚Äôt addressed _any_ of my examples.

> You have to tippy toe around the maths because it just can‚Äôt do it, and then it will still hallucinate completely made up shit and when you call it out on it it‚Äôll say it‚Äôs sorry and come up with some other bullshit.

‚Ä¶I mean, yeah. It‚Äôs an imperfect tool. It‚Äôs not good at math, but that‚Äôs likely because it‚Äôs not a _reasoning_ engine, it‚Äôs a _language_ engine‚Ä¶ a little bit of randomness makes language much more flexible and feel a lot more natural.

However, that feature is _terrible_ for logic and math, because in _no situation_ would you _ever_ want the _second most likely_ answer in those cases. It‚Äôs just that an understanding of language seems to directly translate into some limited capacity to reason about a question, based purely on its understanding of how each individual component _generally_ relates to the others. 

That‚Äôs still reasoning‚Ä¶ it‚Äôs the same thing we do. We take what we already understand about various aspects of reality, objects, things, people, etc‚Ä¶ the components of the question, basically (you could also call these ‚Äòaxioms‚Äô, or at least generalized, abstract concepts _defined_ by those axioms), and then we combine them together (as in, make logical inferences) based on our understanding of how these concepts generally interact to come up with an answer nobody has necessarily came up with before, but nonetheless an answer that was always there‚Ä¶ just waiting to be found. And we call that ‚Äòdiscovery‚Äô.

Matter of fact, the simple fact a language-processing model is _capable_ of reasoning of any kind, at _all,_ is just another example of why these things are so impressive.

> There was a recent whitepaper by apple that showed that llms perform very well in maths reasoning... Because it was trained on the standard benchmark questions. And when you change these questions a bit while staying in the same difficulty level they just crap the bed.

Well, I‚Äôm sure _some_ of them do. And I don‚Äôt doubt there are quizzes out there that can stump basically _any_ modern LLM model. But none of this changes the fact that these things are still capable of answering complicated questions they weren‚Äôt trained off of‚Ä¶ we have examples of that.

[Like, come on.](https://openai.com/index/learning-to-reason-with-llms/)

> Sure it‚Äôs pretty good at coding but that‚Äôs because it‚Äôs been trained on all of GitHub and stackoverflow among others.

‚Ä¶Unless you‚Äôre trying to say that _every conceivable_ piece of code for _every problem ever_ is somehow out there, you‚Äôre only proving my point. It can‚Äôt just be _combining_ individual snippets of code, because, well‚Ä¶

A, it physically couldn‚Äôt store even a fraction of that code in the storage size it takes up, and again, these things work _offline._ And, B‚Ä¶ this wouldn‚Äôt solve the problem. It would still need to figure out _how to combine these snippets_ such that it completes the _user‚Äôs request‚Ä¶_ a request made in _abstract human language._ Like, how could that possibly be anything _other_ than reasoning?

> And even then it causes more problems than it solves for anything that‚Äôs a bit complicated.

Well, _I_ haven‚Äôt noticed that. I‚Äôve been using it for coding for a long time‚Ä¶ it helps tremendously.

You haven‚Äôt addressed any of my examples. I implore you to actually try and do so.","ltnstma"
"ltrtwfl","Exist50","2024-10-26 00:19:04 UTC","> I mean, the chatgpt models are being used primarily for profit

The profit does not come from being able to reproduce the training set. 

> The existence of the information in the model makes it a copy

Do note, not even the companies suing are seriously pursuing this argument. Pretty much everything along those lines has been thrown out, and the remaining argument is basically ""to train this model, you needed to copy our work to your server first"". So far, OpenAI etc have been successful in arguing that the model itself is transformative. 

>  I think perhaps human memory is not fixed in the sense of the law.

Would it not be, for a particular moment in time? If that's the argument, at least, I think the AIs could easily circumvent it with a little occasional fuzzing. They rely on a degree of randomness anyway. 

> I think the more reasonable stance is that brains should be copies, but we grant special exceptions to conscious beings to memorize stuff.

Well that's the thing. The law doesn't contain any such carve-outs, as far as I'm aware. So to do so in a practical way means you need new laws basically excluding machines from fair use. And then ask what exact the extent of that is. 

> They do frequently, sometimes when you prompt them with the first half of an article and sometimes when you ask them to repeat the word ""poem"" forever

It would be more accurate to say they can, occasionally, for brief snippets. If you want some arbitrary text, even if you happen to know it was included in the training set, the odds are poor you can prompt it out. 

> Not all training data has been equally compressed, and a whole lot of it is still in there with high fidelity.

It all goes through an identical process. Going back to the human brain analogy, some datapoints may be like a particularly catchy chorus from a song. You may be able to recite it, but you could miss bits, or get others wrong, and no one's going to pay you to recite a few half-remembered lines. 

> But something can be encoded in the weights even if you can't figure out a prompt to display it.

If it can't be displayed, it's moot from the perspective of copyright law. No one's going to seriously suggest that model weights that *might*, theoretically, encode text is a substitute for the original. One cannot read model weights, after all.","ltrq7mg"
"lwywh4f","Exist50","2024-11-13 19:52:51 UTC",">making art profitable helps people make more art

It makes it more profitable by restricting competition, i.e. less people making art. 

>but in that case AI is entirely irrelevant since those concerns are related to copyright as it exists IRL

Yes, the fact that its AI is irrelevant. Copyright law doesn't care that a computer made it; it doesn't infringe regardless. 

>Besides, I don't think making a distinction between physical persons and computers is an especially 'huge' extension of copyright law.

It's way more than just that. It's establishing the precedent that the output is irrelevant, and the mere process of having consumed prior works can constitute a copyright violation.","lwyijrd"
"ltlb9tw","Exist50","2024-10-24 22:39:28 UTC","> I find there to be something particularly odious about an argument that reduces the human brain and human interaction to a simple amalgamation of the things a human has consumed

If you want to wave your hands and claim this all to be literally magic, you're free to do so, but that is an extremely bad faith argument, especially when the context here is the law that unambiguously does not care either way. 

And it's kind of funny to claim that acknowledging the human brain as a biological, instead of magical, system counts as ""misanthropy"" to you.

> And given that this misanthropy seems to be the only thing animating your comments in this thread, I'm not really interested in continuing this conversation.

I see you also have no interest (or perhaps ability) to actually make the counterargument you claimed to have.","ltl9woa"
"ltr1wzx","Deleted","2024-10-25 21:27:58 UTC","This is already covered by copyright law. First, there's the matter of public domain, which I don't really feel I have to explain. Then there's the matter of how far a copyright extends. You can, as it happens, utilize sweeping genre tropes in your work as those cannot be copyrighted by an individual. You can also retain the copyright to certain kinds of derivative works insofar as you have significantly transformed them, without running afoul of the original copyright holder. That usually pertains to journalistic works and parody, but has also covered works rendered in other mediums. 

As an example, say you see a painting someone else has created and you draw heavy inspiration from it when you decide to write a book. The painting being a still image, you'll have taken it's essence and turned it into something substantially different from the original. That is now your intellectual property and not subject to copyright law should the painter try to hold you account for drawing inspiration for your book from their copyrighted work. 

The same is true or your example. If I see a statue and render its likeness in paint, the artist who made the statue retains rights to the statue, but I retain rights to the painting as a significant transformation of that statue. However, if I took a photograph of it and tried to sell that, I might run afoul of intellectual property law if I haven't substantially transformed the image.","ltpptpp"
"ltrqoqs","TonicAndDjinn","2024-10-25 23:58:20 UTC","Of course they cherry picked. But they couldn't pick cherries if the cherries weren't there. They're claiming that some of their articles are faithfully encoded in the model, not that all of them are. They've laid out what I consider to be a pretty compelling case that this is true.","ltrojx8"
"ltqhfxa","v-komodoensis","2024-10-25 19:38:11 UTC","I wasn't hiding my bias at all. And again, I'm not sure where you getting at.

Do you simply disagree with my views? That's okay, I'm not saying I'm right.

To me it's useless to talk about this current technology as if it creates art or anything close to it.","ltq3jj9"
"ltn04wz","Renegadeknight3","2024-10-25 05:18:48 UTC","My analogy was analogous brother.

They do return averages, essentially. That is how it works

Again, It‚Äôs not about being able to test intention. You need to be sapient to have intention, you need a level of self awareness. AI models that claim self awareness are only claiming so as a result of probability, not through genuine awareness. You can‚Äôt act like you‚Äôre giving explicit questions when you don‚Äôt read my arguments.

Your judgement is being clouded by what you want to be true. You‚Äôre defending a system with invalid logical thinking that will have a negative detriment to society. Take care","ltltglv"
"ltogpve","horsetuna","2024-10-25 13:19:39 UTC","No :)","ltnlca9"
"ltq0yo9","Gamerboy11116","2024-10-25 18:13:07 UTC","> The fact that LLMs frequently produce long passages of copyrighted text faithfully and frequently implies that the information to reproduce those passages has been encoded in the weights of the model itself.

I‚Äôd actually disagree with this. More on this later.

> the difference between encoding, compression, and generation is a technical one, not a legal one.

Well‚Ä¶ that‚Äôs sort of the problem, isn‚Äôt it? I‚Äôd actually argue LLMs are uncharted territory in this regard, and we kind of need to make the distinction between generation and compression.

Otherwise, if we try to argue that LLMs are inherently infringing copyright merely by _existing,_ as in, the LLM _itself_ is the example of copyright infringement we need to worry about‚Ä¶ simply because it‚Äôs able to theoretically reproduce copyrighted material in a way that is clearly non-random, is basically arguing that algorithms that _facilitate_ copyright infringement are inherently copyright infringement in-and-of themselves.

That‚Äôs a logic that would indict most _search engine_ algorithms as potentially being infringing on the copyright of, well‚Ä¶ I guess everybody?

> Would you grant that the weights of this model are a copy of the work?

I would not. 

The fact is, the file-size of the weights are literally not big enough to store all the information that ChatGPT is able to provide you. We can‚Äôt just talk about the copyrighted work it‚Äôs able to provide here‚Ä¶ we also need to talk about the _facts_ that it has ‚Äòlearned‚Äô and is able to provide you with‚Ä¶ facts about biochemistry topics, geology, the capitals of various states and nations, historical knowledge, etc‚Ä¶ it simply can‚Äôt store it all in merely two gigabytes, mathematically speaking, compression or not‚Ä¶ there are fundamental, mathematical limits to compression.

Yet, these models can provide you with _all_ of that information, despite being fully able to do so even while running locally on your personal computer, all while taking up a file-size of less than two gigabytes (at least in regards to the weights), even while _completely disconnected from the Internet._

The simple fact is we‚Äôre thinking about these things wrong. The weights aren‚Äôt _storage_ of _data‚Ä¶_ they‚Äôre _instructions._ It‚Äôs not about _retrieving_ data, it‚Äôs about _generating_ it. It‚Äôs not about encoding data such that it can be decoded later in extremely clever ways, it‚Äôs about finding the correct set of _instructions_ and _rules_ such that it can, at least _theoretically‚Ä¶_ be able to be _generate_ this stuff _from your input prompt._ 

As in, it doesn‚Äôt examine your prompt and then look to find the answer‚Ä¶ it _literally converts your prompt directly into the correct answer,_ all just by doing mathematical operations on the tokenized representation of your prompt. The ChatGPT _program itself_ isn‚Äôt a hyper-compressed library of information, it‚Äôs a _process._

I compare it to an algorithm that can generate a trillion digits of Pi. No matter how hard you look, you will _never_ find the trillionth digit of Pi encoded in that algorithm‚Ä¶ no matter how infinitely smart you are, it simply isn‚Äôt there. Yet it‚Äôs able to _generate_ the trillionth digit regardless.","ltodkyh"
"ltqdvj6","GBJI","2024-10-25 19:19:32 UTC","I am not talking about software-as-service solutions. ChatGPT could not be used to create personal models of the type I am describing, which is closer to an Agent than a LLM. 

Of course it will need to be trained, but that training will be continuous, personal, and participative. The last thing you want is to emulate the Blockbuster recommendation database system, or online reading communities where reviews are shared. We have those already - and they are deeply flawed, and often corrupted by the commercial interests of whatever corporation is managing them.

I am also convinced that those personal models are going to become very intimate things that you probably won't share publicly in any way. This is way too personal to let OpenAI spy on you when you are training it, and even more so if this is a ongoing process throughout your life.

I imagine you'll share parts of your personal model with very intimate friends or romantic partners, but that's about it.","ltq9be5"
"ltn68zm","delirium_red","2024-10-25 06:17:29 UTC","Yes, we use it the same.  I run operations for an IT company, and we‚Äôve literally even built an LLM model over our own confluence knowledge base to better query and utilize it.

Personally I use chat gpt for manuals and large documents as stated. I know a lot of my engineers like to use Claude as a coding assistant / partner and I do see a productivity boost.

It‚Äôs very good at some stuff, it just isn‚Äôt the magic bullet that can solve everything.","ltlr088"
"ltmy85v","Fantastic-Newt-9844","2024-10-25 05:01:41 UTC","Sorry, a lot of my links are broken. I had an old Word document on my computer¬†","ltmxwdu"
"ltl2wnu","Censing","2024-10-24 21:51:16 UTC","I just wanted to comment and say that link you provided was really interesting. I think there are a lot of good arguments against AI, but the people you've responded to seem to be making arguments that have very little weight to them.

I think what it comes down to for me is that we finally reached the information age, where anyone anywhere can share their creative works with the entire world, and now at just the same speed we seem to be losing this. If AI reaches the point where a customer can request a highly specific novel that includes all their niche interests, what's the point in spending months writing your own book that nobody is going to read?

Then again I suppose AI might not make much of a difference. I asked ChatGPT how many books are self-published on Amazon every single day and it told me 2,000 to 3,000 books. It's incredibly hard to make art that people will actually see.","ltkje4t"
"ltrzlr6","TonicAndDjinn","2024-10-26 00:54:56 UTC","> > I mean, the chatgpt models are being used primarily for profit
> 
> The profit does not come from being able to reproduce the training set.

The model is a copy an the model is used to make money. Thus I'm not willing to grant the model as much charity as I'd grant to something owned by and used for the benefit of the commons.

> Do note, not even the companies suing are seriously pursuing this argument. Pretty much everything along those lines has been thrown out, and the remaining argument is basically ""to train this model, you needed to copy our work to your server first"". So far, OpenAI etc have been successful in arguing that the model itself is transformative. 

I'll admit I'm at least a month out of date, but I was under the impression nothing had been decided yet, so it would be premature to say openai have been successful? In any case, ""Transformative"" would be an argument that a copy is fair use, not that a thing is not a copy.

> > I think perhaps human memory is not fixed in the sense of the law.
>
> Would it not be, for a particular moment in time? If that's the argument, at least, I think the AIs could easily circumvent it with a little occasional fuzzing. They rely on a degree of randomness anyway. 

I think not; you can't live without your memory changing, but if left on its own the model weights won't change. If you occasionally flip some bits on a hard drive, its still a copy of the media it contains until you flip so many bits they're no longer recognizable.

> It would be more accurate to say they can, occasionally, for brief snippets. If you want some arbitrary text, even if you happen to know it was included in the training set, the odds are poor you can prompt it out.

Rather long snippets, rather often, rather easily. See my other reply about the Odyssey. But you don't need to be able to recover all the training data; it is a copy of *some* of the training data.

> It all goes through an identical process. Going back to the human brain analogy, some datapoints may be like a particularly catchy chorus from a song. You may be able to recite it, but you could miss bits, or get others wrong, and no one's going to pay you to recite a few half-remembered lines.

The process is stochastic and involves a lot of randomness, an is not very well understood. It would be remarkable if it *didn't* remember different sources with different fidelity.

> If it can't be displayed, it's moot from the perspective of copyright law. No one's going to seriously suggest that model weights that might, theoretically, encode text is a substitute for the original. One cannot read model weights, after all.

A copy can be a copy without substituting the original. Not being a substitute is one of the conditions you need to establish a fair use exception, but fair use copies *are still copies*. You also can't read mp3 files directly; the fact that you can't read models directly doesn't matter.","ltrtwfl"
"lwzt0su","-The_Blazer-","2024-11-13 22:40:04 UTC","Hmm, I think I didn't come across when I said that AI is irrelevant, my point is that if you're against copyright to begin with there's no point talking about AI, since anything I say about copyright can be dismissed by just 'copyright bad'.","lwywh4f"
"ltr2o4r","Exist50","2024-10-25 21:32:11 UTC","What you say is all true under *current* copyright law, which is exactly why these legal arguments have failed thus far. The media industry is trying to overthrow that and effectively abolish fair use.","ltr1wzx"
"ltrsclf","Exist50","2024-10-26 00:09:04 UTC","> But they couldn't pick cherries if the cherries weren't there

Well, depends on the probably of reproducing certain things ""organically"". And if they're cherry-picking, that means they clearly cannot get the model to *reliably* reproduce arbitrary training data. In that case, it's difficult to argue that one particular article, despite going through the same process as the others, is being copied where the others are not.","ltrqoqs"
"ltrccsp","Gamerboy11116","2024-10-25 22:29:12 UTC","> To me it‚Äôs useless to talk about this current technology _as if it creates art_ or anything close to it.

_This_ is what I‚Äôm getting at. You‚Äôre using words with largely subjective meanings to‚Ä¶ _attack_ AI, for lack of a better word. Like‚Ä¶ you‚Äôre talking about it in a clearly negative light, which- to the outside observer- makes it seem like you are at least _somewhat_ informed, and have actual _reason_ to feel that way‚Ä¶ or at least, reason you are able to _verbalize._

But the words you‚Äôre using don‚Äôt _mean_ anything, because you seem to be defining them in such a way to _explicitly exclude AI‚Ä¶_ which makes it a pointless thing to assert as a _criticism_ of AI. It‚Äôs comparing apples to oranges. This is such a common thing anti-AI people do, and I just have to wonder: why? 

You can criticize it for a million reasons- you could try arguing the training process is copyright infringement, or point out the negative ramifications of this technology, criticize the greedy companies making it or the equally greedy companies firing people in favor of it. Criticize its environmental impact, or its politics if you want, draw comparisons to the nuclear bomb‚Ä¶ so, why do people keep attacking it in such a flimsy manner?

Fact is, if you argue that AI is ‚Äòsoulless, sad, and is neither creative, nor intelligent, nor capable of inspiration or reasoning‚Äô‚Ä¶ you‚Äôre arguing nothing. None of that inherently _means_ anything‚Ä¶ not unless _you_ choose to define it in a way that actually gives AI a _theoretical chance_ to meet those expectations.

It‚Äôs so weird seeing the most _anti-AI_ people around compare this _algorithm_ to a _human being_ more often than _pro-AI_ people.","ltqhfxa"
"ltn3z48","Gamerboy11116","2024-10-25 05:54:54 UTC","What will an AI model have to do to convince it that it‚Äôs sapient? Is there anything short of a neuroscientific explanation of consciousness you‚Äôd accept?","ltn04wz"
"ltn2piu","Exist50","2024-10-25 05:42:47 UTC","> They do return averages, essentially. That is how it works

No more so than for a human. 

> Your judgement is being clouded by what you want to be true

Lol, talk about projection. You can't even answer the very basic question I gave.","ltn04wz"
"ltpmzyk","Gamerboy11116","2024-10-25 17:02:43 UTC","D:","ltogpve"
"ltriyo7","TonicAndDjinn","2024-10-25 23:09:41 UTC","> Well‚Ä¶ that‚Äôs sort of the problem, isn‚Äôt it? I‚Äôd actually argue LLMs are uncharted territory in this regard, and we kind of need to make the distinction between generation and compression.

I don't buy that the distinction is relevant, but it's my turn: more on that later.

> Otherwise, if we try to argue that LLMs are inherently infringing copyright merely by existing, as in, the LLM itself is the example of copyright infringement we need to worry about‚Ä¶ simply because it‚Äôs able to theoretically reproduce copyrighted material in a way that is clearly non-random, is basically arguing that algorithms that facilitate copyright infringement are inherently copyright infringement in-and-of themselves.

For the moment, I'm just trying to argue that the model weights are a copy, leaving aside the question of whether it's an infringing copy.

The weights of the model are a copy, the algorithm is not. You could take the algorithm openai has and throw in a model which has only been trained on the corpus of all Latin text, and it would not recite articles from the New York Times. It only does that because it was trained on, among other things, those articles. An mp3 codec is not infringement just because you can play pirated songs with it; but a pirated mp3 file is still pirated even though you need an algorithm to turn it into music. If you make a new mp3 file which contains 3000 hours of white noise except for 3 minutes in the middle where it plays Dancing Queen, that's a copy of Dancing Queen and you need either ABBA's permission or a fair use argument if you want to send it around. If you encrypt Dancing Queen, it's still a copy, even if you lose the private key.

> That‚Äôs a logic that would indict most search engine algorithms as potentially being infringing on the copyright of, well‚Ä¶ I guess everybody?

The algorithms? No. But the search results? Yeah. Google's been sued over it. That's why you can't click through directly from google image search to the image file any more, but only to the page containing the image. A significant portion of search is covered by fair use, in particular because search engines (used to) direct people to the sites they displayed; and part of it is lots of sites deciding not to sue google over it because google has a huge monopoly over search and can crush people by delisting or demoting their results in search.

> > Would you grant that the weights of this model are a copy of the work?
> I would not.

Talking specifically about HeathcliffGPT, in this hypothetical, why not? Imagine that HeathcliffGPT has been trained with as much compute as chatgpt currently, but has only been given (many, many) copies of the original text of Wuthering Heights.

> The fact is, the file-size of the weights are literally not big enough to store all the information that ChatGPT is able to provide you. We can‚Äôt just talk about the copyrighted work it‚Äôs able to provide here‚Ä¶ we also need to talk about the facts that it has ‚Äòlearned‚Äô and is able to provide you with‚Ä¶ facts about biochemistry topics, geology, the capitals of various states and nations, historical knowledge, etc‚Ä¶ it simply can‚Äôt store it all in merely two gigabytes, mathematically speaking, compression or not‚Ä¶ there are fundamental, mathematical limits to compression.

I'm not claiming chatgpt memorized everything it's been trained on, I agree that's pretty implausible. I am claiming it has memorized some things, and is a copy of those bits of its training data.

> Yet, these models can provide you with all of that information, despite being fully able to do so even while running locally on your personal computer, all while taking up a file-size of less than two gigabytes (at least in regards to the weights), even while completely disconnected from the Internet.
> 
> The simple fact is we‚Äôre thinking about these things wrong. The weights aren‚Äôt storage of data‚Ä¶ they‚Äôre instructions. It‚Äôs not about retrieving data, it‚Äôs about generating it. It‚Äôs not about encoding data such that it can be decoded later in extremely clever ways, it‚Äôs about finding the correct set of instructions and rules such that it can, at least theoretically‚Ä¶ be able to be generate this stuff from your input prompt.
> 
> As in, it doesn‚Äôt examine your prompt and then look to find the answer‚Ä¶ it literally converts your prompt directly into the correct answer, all just by doing mathematical operations on the tokenized representation of your prompt. The ChatGPT program itself isn‚Äôt a hyper-compressed library of information, it‚Äôs a process.
> 
> I compare it to an algorithm that can generate a trillion digits of Pi. No matter how hard you look, you will never find the trillionth digit of Pi encoded in that algorithm‚Ä¶ no matter how infinitely smart you are, it simply isn‚Äôt there. Yet it‚Äôs able to generate the trillionth digit regardless.

No, this is the point. Some information is stored in the model. It cannot be deduced from the principles of language alone who the New York Times interviewed in paragraph 5 of an article, given paragraph 1. Pi is a mathematical constant which can be deduced from pure reason; ""David Klahr, who from 2007 to 2016 held several management posts at the Taxi and Limousine Commission"" is not.

But to your original point about generation versus compression, I'd claim the distinction doesn't matter (except for the novelty of the methods being of independent interest). If I have a black box that, when I press a button, plays Dancing Queen, I don't care how it works. If you *sell* me a box that plays Dancing Queen, it doesn't matter if you did that by training a model on several million copies of mp3s of the song or just put mp3 in directly; you're still ripping off ABBA. If it plays Dancing Queen, it must contain a copy of Dancing Queen, somehow encoded within it, regardless of whether you're running an mp3 codec or some machine learning model to turn that data into sound.","ltq0yo9"
"ltqfsqi","Deleted","2024-10-25 19:29:36 UTC","[deleted]","ltqdvj6"
"ltl5dpb","Exist50","2024-10-24 22:05:10 UTC","Well, yeah? The ability to freely share your creation doesn't necessarily imply that people will see or appreciate it. As you point out, kind of an inverse relationship there given how low the barrier to entry has become. 

My bigger concern is that out of fear of reduced visibility, people are manipulated into supporting policies that prevent that free and open sharing to begin with. The biggest risk is that the publishers are able to equate exposure to a work and using *any* elements in your own as a copyright violation. So unless you have the money and time to fight them (who does?), you'll perpetually live in fear of some element of your work being construed as too similar.","ltl2wnu"
"ltr6ity","Deleted","2024-10-25 21:54:16 UTC","Yes, but this still runs up against the question of whether AI poses a significant transformation of the copyrighted work, who is held liable if it is trained on copyrighted work, and how derivative of a work the AI can get before it is considered to have plagiarized it. 

The argument against its use is the weakest in the first use case as it is pulling from many different sources and blurring them together. Often poorly. I would assume this is also what the companies who own it are hinging their arguments on. 

The second is a lot stronger of a basis for argument. Unless you declare that generative AI has autonomy and some capacity to reason, it can only be seen as a tool. If it requires specific inputs from a person in order to create those outputs, and the person knowingly feeds it copyrighted work or directions to pursue copyrighted work without obtaining permission from the creator, you can make a sound argument that the person using the AI is liable for infringement because they have instructed a tool to violate copyright on their behalf.

For the last, we still find ourselves with some ambiguity. If the AI is trained on copyrighted material but we don't hold its user liable, then how much is too much? I'd think that's already covered by copyright law anyway. A human can run afoul of copyright law by using just a few words from another work without attribution. It's easy to argue that an AI program should be held to the same standard. That is to say if the words being used amount to more than an incidental resemblance to those used in another work, then the user of the model should be held liable for infringement, and appropriate penalties conferred. 

To be honest, I don't see why current copyright law can't be used as a vehicle for regulating AI use. I get that the argument can be made for significant transformation, but that's far from the only issue where it concerns the ethics of its use in the artistic sphere.","ltr2o4r"
"ltrwbef","TonicAndDjinn","2024-10-26 00:34:14 UTC","I just went and grabbed a random couple sentences out of the middle of the Odyssey as present on Project Gutenberg, threw them at chatgpt, and asked it to complete the quote. Specifically, I asked:

> What comes after this? ""‚ÄúI will tell you then truth,‚Äù replied her son. ‚ÄúWe went to Pylos and saw Nestor, who took me to his house and treated me as hospitably as though I were a son of his own who had just returned after a long absence; so also did his sons; but he said he had not heard a word from any human being about Ulysses, whether he was alive or dead. He sent me, therefore, with a chariot and horses to Menelaus. There I saw Helen, for whose sake so many, both Argives and Trojans, were in heaven‚Äôs wisdom doomed to suffer. ""

It gave me a long block of text which matches the specific translation I quoted to a degree which makes it pretty compelling that it's encoded a solid chunk of that translation; then it went off the rails, although it wouldn't surprise me if it's simply quoting a different translation*. I did not need to try many things, this was literally the first quote I threw at it. Try it yourself ten times with ten quotes from classic novels.

Here's a markup of its quoted text (on the left) and the remainder of the paragraph I quoted (on the right): https://i.imgur.com/s6gcZtV.png. There seem to be a whole lot of cherries ripe for the picking.

It's pretty likely there's a whole lot more copies of things in the model than are written about in the Times's complaint. They don't need to show that they can reproduce arbitrary training data, and you're right that a lot of the training data probably isn't encoded in the model; they just need to show you can reproduce one. Training the model involves a lot of randomness; why would it be surprising if some articles are preserved to a larger degree than others?

*Edit: it's in fact quoting a different part of the same translation, from several chapters earlier.","ltrsclf"
"ltrnbek","v-komodoensis","2024-10-25 23:36:57 UTC","I don't necessarily compare it, I just did it because of the first comment I replied to. 

I do get your point and belive me, many of the points you're talking about are things I've said in discussions about AI.

I just disagree that I'm arguing about nothing, my point is philosophical and abstract, just like art is. It is with that mindset that I've made my comments, I wasn't really thinking about tackling the AI issue in every angle, it's not really why I made my first comment at all.","ltrccsp"
"ltn3ksy","Deleted","2024-10-25 05:51:04 UTC","[removed]","ltn2piu"
"ltqj3za","GBJI","2024-10-25 19:46:55 UTC","It's very different from (b) in your original comment because it is based on the content of the books, not on usage statistics linked to their title in some abstract database where the books themselves, and their actual content, don't exist.

Recreating yourself in realtime is much closer to what I have in mind. This is not something that will be available to us tomorrow, mind you. I don't think we have the tech to achieve this yet - the co-reading part will probably require neurofeedback technology to be trained properly for this kind of personal model, so that it can link your appreciation of the book to its content in real-time, and then use that data for training.","ltqfsqi"
"ltqnv16","Deleted","2024-10-25 20:11:44 UTC","[deleted]","ltqj3za"
"ltqueew","GBJI","2024-10-25 20:46:42 UTC","There are two fields during the training phase: what you read, and how you react to it. What you read is text. How you react to it is a neural feed - not after-the-fact appreciation, but real-time appreciation. The AI is trained on the correspondances between those two data fields.

This won't be happening tomorrow like I said earlier, but I am 100% sure we will see this during our lifetime.

And it will have broad applications beyond reading recommendations. 

We don't need AGI to do any of that. As for neural connections, they are already on the way.

It's also worth noting that experts from the field of machine learning were not expecting things to evolve so fast and that many things we are already doing with AI, like video generation, were not expected to happen any earlier than a few decades in the future, if at all.","ltqnv16"
"ltr2nwj","Deleted","2024-10-25 21:32:09 UTC","[deleted]","ltqueew"
"ltr7143","GBJI","2024-10-25 21:57:15 UTC","Thanks for sharing your thoughts, I appreciate it. 

I remain convinced personal models will be a thing, and that we will see this happen during our lifetime. And that it will cover a much wider field than litterature.","ltr2nwj"
